<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cheetaher Blog</title>
    <description>Every failure is leading towards success.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 03 Jun 2020 10:06:47 +0800</pubDate>
    <lastBuildDate>Wed, 03 Jun 2020 10:06:47 +0800</lastBuildDate>
    <generator>Jekyll v4.1.0</generator>
    
      <item>
        <title>2019-08-30-基于单目相机得2D地图构建</title>
        <description>&lt;ul&gt;
  &lt;li&gt;同时定位和建图（SLAM）是机器人和自主导航中的一个重要领域，目前常见的SLAM有基于视觉、激光雷达、以及多传感器混合等方式。视觉SLAM因为缺少3D信息，其对于3D场景的结构必须通过结合多组不同视角的图像进行推断，具有较大的挑战性。ORBSLAM2是一种常用的视觉SLAM系统，它能够使用单目摄像机创建基于点云的地图，也就是可以获得环境的3D结构。但是获得的是稀疏点云，地面移动机器人并不能通过这种稀疏点云进行导航，本文针对这个问题，研究了如何基于稀疏点云地图实现二维的栅格化地图以用于实际机器人的导航。本文提出了一种将3D点云投影到2D平面构建概率图，然后对概率图阈值化获得2D地图的方法。最终的实验结果表明本文方法建立的二维地图具有较好的准确度以及实用性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;一背景介绍&quot;&gt;一、背景介绍&lt;/h2&gt;
&lt;p&gt;同时定位和建图（SLAM）是机器人和自主导航中的一个重要领域。它是指机器人在未知环境中移动并使用其传感器和里程计信息构建环境地图并同时估计其在此地图中位置的过程。SLAM对于机器人系统的自动操作是不可或缺的，如室内的自动扫地机器人与室外复杂环境下的自动驾驶汽车。使用像LiDAR和Kinect这样的复杂3D传感器进行SLAM目前已经有了较为成熟的技术方案，尤其是在大多数的室内环境中进行SLAM已经有了比较完善的方法$^{[1]}$。然而，这些3D传感器诸如LiDAR的高成本和Kinect的有限识别范围之类的限制，使得LiDAR不能用于低成本的SLAM系统而Kinect则难以用于户外场景。因此，视觉SLAM（一个或两个2D摄像机用作传感器）仍然是一个很受欢迎的研究领域。但同时这也是非常具有挑战性的，因为缺少直接的3D信息，所以场景的3D结构必须通过从不同视角拍摄的多个图像中提取特征来进行推断。但是有时即使在存在3D传感器的情况下也需要来自相机的丰富视觉信息进行环闭检测。所以如果通过相机获得的3D信息也可以用于地图生成和定位，则可能大大的提高系统的性能。
ORB-SLAM $^{[2][3]}$ 是一种较为成熟的视觉SLAM方案，能够仅使用单目摄像机创建基于点云的地图，在复杂的室外环境下也能有较好效果。虽然ORBSLAM获得的稀疏点云可以用于获得环境的3D结构，但是对于使用需要2D栅格地图$^{[4]}$ 作为输入的路径规划和导航算法而言，这种地图并不能起到作用。ORB SLAM产生的点云是稀疏的，这使得其难以生成包含大部分障碍的栅格图，这些栅格图可以在自由空间中为机器人提供足够的连续性，以保证路径规划的顺利进行。该项目旨在通过使用ORB SLAM产生的3D点云实时构建2D栅格图的方法来解决稀疏点云不能用于导航的问题。栅格地图应该足以使ROS$^{[5]}$的标准导航包使用它来生成导航命令，该命令可以允许机器人（实体或虚拟）跟踪ORB SLAM生成的摄像机轨迹。
Santana等人基于颜色将图片中的区域分为不同的连通域，然后使用由SLAM产生的homograhy矩阵对同一个连通域进行建图。但是这种方法对计算资源的需求比较大，对于需要通过视觉实时建图的系统来说具有较大的困难。另外一种构建地图的方法是将3D的点云信息转化为3D的激光雷达数据，然后调用ROS包，将得到的数据输入到Gmapping节点中。但是这种方法会带来额外的不确定性，对于建图的稳定性具有较大的挑战。
Goeddel等人最近的一项工作$^{[6]}$ 提出了一种从3D LiDAR数据中提取2D地图以进行定位的方法。它的工作原理是通过对估计点所在的平面斜率进行阈值处理，对每个点施加垂直度约束。为了区别出合适大小的障碍物，它使用两个不同的阈值，一个较小的阈值（15度）用于检测导航过程中是否有危险，而较大的一个（80度）用于检测是否会发生碰撞。对障碍检测施加了两个额外的限制以进一步减少错误概率：1.只考虑那些z轴长度在设置范围内的点；2.该点的垂直线中包含的点云的数量需要超过阈值。Huesman$^{[7]}$在将3D点云转换为2D栅格图的过程中也是基于斜率阈值法确定障碍物这一核心思想，本次项目中也使用的方法也将此作为检测虚假障碍的方法之一。&lt;/p&gt;

&lt;p&gt;首先分析了普通单目相机的内外参数，并对使用相机进行了标定。然后介绍了视觉SLAM中几种算法，接着在ORBSLAM2构建的3D点云图上实现了二维地图的构建。并通过实验验证了ORBSLAM2的效果以及构建2D地图的实时性以及准确性。&lt;/p&gt;

&lt;h2 id=&quot;二相机模型及数据获取&quot;&gt;二、相机模型及数据获取&lt;/h2&gt;
&lt;p&gt;目前单目摄像头使用较为普及，普通的单目摄像头一般都可以获得RGB三通道的彩色图像，且其价格较低，故本次项目采用普通的二百万像素的单目摄像头进行。&lt;/p&gt;

&lt;h4 id=&quot;21-相机内参与畸变&quot;&gt;2.1 相机内参与畸变&lt;/h4&gt;
&lt;p&gt;相机将3D世界中的真实点转换到二维图像平面上，为了从图像中复原出3D世界的真实点，我们需要用到相机模型。其中最常用的相机模型是针孔模型，如图2.1。
&lt;img src=&quot;../img/ORBSLAM/camera.png&quot; width=&quot;6000&quot; height=&quot;400&quot; alt=&quot;图片描述文字&quot; /&gt;
在图2.1中，右边为3D世界真实点，左边为相机获得的图像平面上的点。O为模型中的针孔[8]。由于图像是二维平面，因此还有Y坐标，根据相似三角形，有：
\(\frac{Z}{f} = -\frac{X}{X^{'}}=-\frac{Y}{Y^{'} }\)
在这里，图像平面不能表示图像的像素平面坐标，因此，定义像素坐标系o-u-v，而像素坐标是可以直接在图像文件中获得的。通常，像素平面的坐标原点为图像左上角，而图像平面的坐标原点为图像中心，因此两个坐标系存在一个尺度变换和一个平移变换，像素平面o-u-v和图像平面O-X’-Y’的转换关系为：
[\left{ \begin{matrix}
   {u=\alpha X^{‘}+c_x}  &lt;br /&gt;
   {v=\beta Y^{‘}+c_y}  &lt;br /&gt;
\end{matrix} \right.]&lt;/p&gt;

&lt;p&gt;简化模型，转换坐标系，去掉式(2-1)中的负号，并代入式(2-2)，有：
[\left{ \begin{matrix}
   {u=\alpha f_x \frac{X}{Y}+c_x}  &lt;br /&gt;
   {v=\beta f_y \frac{Y}{Z}+c_y}  &lt;br /&gt;
\end{matrix} \right.]
转化为矩阵形式有：
[Z\left( \begin{matrix}
   u  &lt;br /&gt;
   v  &lt;br /&gt;
   1  &lt;br /&gt;
\end{matrix} \right)=\left( \begin{matrix}
   {f_x} &amp;amp; {0} &amp;amp; {c_x}  &lt;br /&gt;
   {0} &amp;amp; {f_y} &amp;amp; {c_y}  &lt;br /&gt;
   {0} &amp;amp; {0} &amp;amp; {1}  &lt;br /&gt;
\end{matrix} \right)\left( \begin{matrix}
   {X}  &lt;br /&gt;
   {Y}  &lt;br /&gt;
   {Z}  &lt;br /&gt;
\end{matrix} \right)\triangleq KP]
在式(2-4)中，中间的3×3的矩阵被称为相机的内参矩阵K，内参矩阵反映了3D真实点到图像像素平面的变换关系。通常，相机在出厂后就已经标定好内参了，但是，由于一些外力和机械因素，内参可能会有些许变化。另一方面，当选择让相机输出不同分辨率的时候，内参矩阵也会发生变化，这种变化一般是与分辨率成线性关系的。&lt;/p&gt;

&lt;h4 id=&quot;22-相机外参&quot;&gt;2.2 相机外参&lt;/h4&gt;
&lt;p&gt;相机在三维世界中移动的是一个刚体运动，只有平移和旋转上的变换，没有尺度上的变换，因此属于欧氏变换$^{[9]}$，如图2.2，w下标的是世界坐标系，c下标的是相机坐标系.
&lt;img src=&quot;../img/ORBSLAM/odom.png&quot; alt=&quot;&quot; /&gt;
使用旋转矩阵R与平移矩阵t表示这一变化如式2.5。
[\left( \begin{matrix}
   x_w  &lt;br /&gt;
   y_w  &lt;br /&gt;
   z_w  &lt;br /&gt;
   1    &lt;br /&gt;
\end{matrix} \right)=\left( \begin{matrix}
   {R} &amp;amp; {t}   &lt;br /&gt;
   {0} &amp;amp; {1}   &lt;br /&gt;
\end{matrix} \right)=T\left( \begin{matrix}
   {X}  &lt;br /&gt;
   {Y}  &lt;br /&gt;
   {Z}  &lt;br /&gt;
   {1}  &lt;br /&gt;
\end{matrix} \right)]
其中T表示旋转平移矩阵，也就是相机的外参。相机的外参也就是相对于世界坐标系的欧氏变换矩阵，它描述了相机相对于世界坐标系的相对位置和姿态，也就是平移和旋转量。我们要做的定位系统实际上就是为了实时求得相机的外参矩阵，如何求解这个矩阵是整个系统的核心问题.&lt;/p&gt;

&lt;h4 id=&quot;23-相机标定&quot;&gt;2.3 相机标定&lt;/h4&gt;
&lt;p&gt;相机标定已经有了较为成熟的方案，本文采用张氏标定法进行相机内外参数的标定。”张正友标定”是指张正友教授1998年提出的单平面棋盘格的摄像机标定方法[1]。文中提出的方法介于传统标定法和自标定法之间，但克服了传统标定法需要的高精度标定物的缺点，而仅需使用一个打印出来的棋盘格就可以。同时也相对于自标定而言，提高了精度，便于操作。因此张氏标定法被广泛应用于计算机视觉方面。
本文基于opencv，采用张氏标定法对相机进行标定，最终得到相机内参如表2-1.其中fx,fy表示相机的焦距，cx和cy表示的是相机的几何光轴(反映在图像平面上就是图像原点)相对于像素平面的像素偏移量。&lt;/p&gt;

&lt;p&gt;| $F_X$ | 535.4 | 
| :—–| —-:  | 
| $F_Y$ | 539.2 | 
| $C_X$ | 320.1 | 
| $C_Y$ | 247.6 |
所以相机内参矩阵为：
[\left( \begin{matrix}
   {f_x} &amp;amp; {0} &amp;amp; {c_x}  &lt;br /&gt;
   {0} &amp;amp; {f_y} &amp;amp; {c_y}  &lt;br /&gt;
   {0} &amp;amp; {0} &amp;amp; {1}      &lt;br /&gt;
\end{matrix} \right)=\left( \begin{matrix}
   {535.4} &amp;amp; {0} &amp;amp; {320.1}  &lt;br /&gt;
   {0} &amp;amp; {539.2} &amp;amp; {247.6}  &lt;br /&gt;
   {0} &amp;amp; {0} &amp;amp; {1}      &lt;br /&gt;
\end{matrix} \right)]&lt;/p&gt;

&lt;h2 id=&quot;三算法介绍&quot;&gt;三、算法介绍&lt;/h2&gt;
&lt;p&gt;主要介绍使用视觉进行SLAM时所使用的主要算法。包括特征的提取，特征的匹配以及如何根据匹配特征求解位姿。&lt;/p&gt;
&lt;h4 id=&quot;31-orb特征与siftf特征&quot;&gt;3.1 ORB特征与SIFTF特征&lt;/h4&gt;
&lt;p&gt;对图像进行帧间运动估计的第一步是获得相邻两帧图像3D特征配对点，选择高准确率、高效率的特征可以有效增加实时定位系统的鲁棒性和实时性。常用的二维特征点有ORB、SURF等，能够在实时视频流处理中使用，是特征点选择的首要指标。
如图3.1所示，特征检测可以分为角点检测、斑状检测和区域检测。在此介绍两种最常用的特征：SURF ( Speeded Up Robust Features, 加速稳健特征)和ORB(Oriented FAST and Rotated BRIEF,有方向的FAST和带旋转的BRIEF)。
&lt;img src=&quot;../img/ORBSLAM/tezheng.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;32-sift特征&quot;&gt;3.2 SIFT特征&lt;/h4&gt;
&lt;p&gt;SIFT(Scale-invariant feature transform,尺度不变特征转换)是图像处理中用途广泛的算法，常用来处理机器视觉中的侦测和描述图像的局部特征。SIFT算法由David Lowe在1999年发表，并在2004年完善总结。后来的PCA-SIFT$^{[10]}$和A-SIFT都是基于SIFT，采用主成分分析技术和改变采样空间衍生出来的算法。
SIFT算法包含SIFT检测子和SIFT描述子，并且具有尺度空间不变性和仿射不变性，对光线、噪声和微小的视差改变的容忍度也很高。因此，这些被提取出来的特征具有非常高的辨识度，很少出现错误匹配的状况。
SIFT首先建立DOG尺度空间，尺度空间的建立是通过将原图像经过带有不同标准差的高斯核进行卷积得到的，由此产生一系列模糊的图像来代替真正的各尺度空间$^{[11]}$。接下来令相邻的尺度空间相减，从而得到差分的DOG空间，如图3.2。由于DOG空间是差分形成的，因此可以用来检测特征点。在DOG空间下，这些特征点与同一层邻近的8个点、上下层相邻的各9个点比较，如果该点比邻近的26个点都大或都小，则认为该点是极值点，也就是待定特征点，如图3.3。
&lt;img src=&quot;../img/ORBSLAM/SIFT.png&quot; alt=&quot;&quot; /&gt;
接下来在选定的极值点中通过泰勒二阶展开去除小于设定阈值的不稳定点，再通过计算剩余极值点的邻域梯度来获得具有旋转不变性的关键点。然后将坐标轴旋转为关键点的方向，确保旋转不变性，通过一个128维的特征向量来作为SIFT描述符。再对这个特征向量进行归一化，从而去除光照变化带来的影响。从SIFT算法中可以看出，由于SIFT算法建立了许多金字塔，造成尺度过大，虽然算法稳定性较好，但是计算时间过长，不适合在实时定位系统中应用。
&lt;img src=&quot;../img/ORBSLAM/DOG.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;33-orb特征&quot;&gt;3.3 ORB特征&lt;/h4&gt;
&lt;p&gt;ORB(Oriented FAST and Rotated BRIEF,有方向的FAST和带旋转的BRIEF)特征，是一种应用于实时视频流处理的特征。ORB特征分为关键点“Oriented FAST”和描述子“Rotated BRIEF”两部分。所以说，ORB特征可以说是FAST特征点的检测方法和BRIEF特征描述子的结合和改进[11]。因此，提取ORB特征分为以下两个步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Oriented FAST关键点提取：找到图像中的关键点，即角点，也就是图像中灰度变化较大的地方。Oriented FAST在FAST的基础上，另外计算了关键点的主方向，为接下来的BRIEF描述子增加了旋转不变的特性。要想判断一个像素点p是不是FAST关键点，只需要判断其周围的16个像素点中是否有连续N个点的灰度值与p的差超出阈值，16个点的位置如图3.4所示。N一般取12，称为FAST-12，常用的还有FAST-9，FAST-11，阈值一般为p点灰度值的20%。找出关键点后，还要计算该特征的方向，使用灰度质心法实现。灰度质心是指一小块图像中以每个像素的灰度值作为权重计算加权后的中心点。如图3.4以p点为中心的小块区域中，根据各个点的灰度值可以计算出一个灰度质心，通常不与p点重合，这样从p点到灰度质心的连线就是这个特征点的方向。
&lt;img src=&quot;../img/ORBSLAM/fast.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;形成BRIEF描述子：根据提取到的FAST关键点，对其周围图像区域进行描述。BRIEF是一种二进制描述子，其描述向量由编码0和1组成。0和1分别编码了关键点附近两个像素a、b亮度之间的大小关系:若Ia&amp;gt;Ib，则取1，反之则取0，其中像素a和像素b的选取则是通过随机分布得到的。ORB算法在FAST特征点提取阶段计算了关键点的方向信息，因此可以利用得到的方向信息，计算旋转之后的“Steer BRIEF”特征，使得ORB描述子具有更好的旋转不变性。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;综上所述，ORB特征使用了FAST和BREIF两种高效算法，并在其基础上进行了改良，拥有较高的效率和鲁棒性，在实时视频流处理中应用十分广泛。&lt;/p&gt;

&lt;h4 id=&quot;34-特征匹配&quot;&gt;3.4 特征匹配&lt;/h4&gt;
&lt;p&gt;特征匹配就是匹配两帧图像之间相同的特征点，然后根据匹配的特征点将两帧图像联系起来。图像之间的特征匹配是通过描述子进行的，其方法就是计算描述子之间的汉明距离，汉明距离越小，两个 ORB 特征就越相似。ORB进行特征匹配的效果如图3.5所示。
&lt;img src=&quot;../img/ORBSLAM/pipei.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;35-位姿求解&quot;&gt;3.5 位姿求解&lt;/h4&gt;
&lt;p&gt;上一节介绍两帧图像之间进行匹配的方法，知道两帧图像之间的关系之后就可以根据这一关系求解出相机在运动中的位姿变换。通过ORB特征进行了帧间相应点的匹配，获得的匹配点具有深度信息，通过匹配点的3D点来计算运动中的位姿变化。假设有一组匹配好的3D点：
[P=\left{ {p_1,…,p_n} \right},P^{‘}=\left{ {p_1^{‘},…,p_n^{‘}} \right}]
对于任意的匹配点，都有相同的欧氏变换R，t：
[\forall i,{ {p}&lt;em&gt;{i}}=Rp&lt;/em&gt;{i}^{t}+t]
上述问题可以用ICP(Iterative Clotest Point,迭代就近点)[12]算法求解。在上一节中，特征点法较好的求解了两帧图像之间的匹配关系，所以，可以用ICP求解相机运动中的位姿变换。ICP的求解分为两种方式：使用线性代数求解，最常用的是SVD（singular value decomposition，奇异值分解）和使用非线性优化方式求解。&lt;/p&gt;

&lt;h2 id=&quot;四3d点云地图的构建&quot;&gt;四、3D点云地图的构建&lt;/h2&gt;
&lt;p&gt;目前视觉SLAM的已经有了很大的发展，有许多优秀的算法都可以实现。比如基于EKF的Mono SLAM，采用关键帧的PTAM，围绕ORB特征计算的ORBSLAM，以及最近提出的许多基于深度学习的VSLAM方案。考虑到计算的实时性以及计算资源的限制，本文选取了ORB_SLAM进行３D地图的构建，其构建的是３D的稀疏点云，其建图的大概效果如图４.１，可以发现基本能把轮廓描述出来，但是并不包含更多的详细信息。
&lt;img src=&quot;../img/ORBSLAM/orbslam.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;41-orbslam２介绍&quot;&gt;4.1 ORBSLAM２介绍&lt;/h4&gt;
&lt;p&gt;ORB-SLAM是Raul Mur-Artal，J. M. M. Montiel和Juan D. Tardos在2015年发表，ORB-SLAM的模块包括跟踪、建图、重定位和闭环检测[13]，但是只支持单目相机。ORB-SLAM2在ORB-SLAM的基础上做出了改进，支持双目相机和RGBD相机。ORB-SLAM2可以计算相机的位姿和轨迹，并对地图进行3D重构。整个系统分为3个线程：跟踪（Tracking）、局部建图（Local Maping）和回环检测（Loop Closing）。其结构如图4.２所示。
&lt;img src=&quot;../img/ORBSLAM/orbslam_arc.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;42-地图构建&quot;&gt;4.2 地图构建&lt;/h4&gt;
&lt;p&gt;ORB-SLAM2系统第一步要初始化，首先选取有足够匹配点的两帧图像，作为参考帧和当前帧，利用这两帧计算基本矩阵和单应矩阵。其中基本矩阵F是由对极几何理论得到的，基本矩阵计算了点到直线的映射，反映了图像到图像的对应关系。单应矩阵H描述了两个平面之间的映射关系，用来计算场景中的特征点落在同一个平面上时的旋转矩阵R和平移矩阵t。从定义可以看出，基本矩阵F和单应矩阵H只差了一个相机内参。
在接下来的地图构建过程中，ORB-SLAM2采用了较为宽松的策略来添加地图点，以达到较高的运行速度。而后续地图点的筛选和优化则用到了闭环检测模块，这部分将在4.5章节中讲述。下面将依次介绍ORBSLAM2中的跟踪线程，局部建图线程以及回环检测线程。&lt;/p&gt;

&lt;h4 id=&quot;43-跟踪模块&quot;&gt;4.3 跟踪模块&lt;/h4&gt;
&lt;p&gt;ORB-SLAM2系统的跟踪模块分为两个子模块：全局重定位和局部地图跟踪。全 度和较高的稳定性。&lt;/p&gt;

&lt;h5 id=&quot;全局重定位&quot;&gt;全局重定位&lt;/h5&gt;
&lt;p&gt;当系统需要初始化位姿估计或局部地图跟踪失败时，需要进行全局重定位。基本流程为：提取当前帧的ORB特征，计算当前帧的BOW向量，然后通过搜索图像数据库中所有关键帧，来寻找适用于重定位的拥有足够多匹配点的关键帧。在这里，图像数据库使用了BOW（Bag-of-words model，词袋模型）。
BOW模型是信息检索领域较为常用的文档表示方法，被广泛应用在文件分类中。词（word）出现的频率可以用来当作训练分类器的特征。在信息检索时，BOW模型忽略一个文档的词的顺序等要素，仅把文档看作是词的集合。&lt;/p&gt;

&lt;h5 id=&quot;局部地图跟踪&quot;&gt;局部地图跟踪&lt;/h5&gt;
&lt;p&gt;当已经计算出了上一帧的位姿后，就不再需要使用全局定位了，这时候，使用局部地图跟踪能够更精确更快速地计算当前帧的位姿，尤其是在地图较大时。
局部地图跟踪的原理：将和当前帧K有相同点的关键帧序列设为K1，将与K1在Covisibility Graph邻近的关键帧序列K2(拥有足够多的相同点的关键帧)。根据K1和K2来匹配当前帧的地图点，最终解算出相机的位姿并优化，流程如图4.3所示。
&lt;img src=&quot;../img/ORBSLAM/tracking.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;44-局部建图&quot;&gt;4.4 局部建图&lt;/h4&gt;
&lt;p&gt;局部建图分为关键帧插入、地图点云筛选、新地图点云创建、局部约束调整和局部关键帧筛选，见图4.3。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;关键帧插入：检测是否有关键帧在序列中，如果有，计算新关键帧的词袋描述子，并插入地图中。&lt;/li&gt;
  &lt;li&gt;地图点云筛选：当地图点出现在足够多的关键帧中时，认为该地图点是稳定点，否则剔除该地图点。&lt;/li&gt;
  &lt;li&gt;新地图点云创建：根据三角化ORB特征向量，计算新点云在地图中的位置，并更新地图。&lt;/li&gt;
  &lt;li&gt;局部约束调整（Bundle Adjustment）：使用Bundle Adjustment优化当前关键帧的位姿。&lt;/li&gt;
  &lt;li&gt;局部关键帧筛选：为了精简关键帧的数量，如果当前关键帧能够被其他三个关键帧看到，且有90%点云相同，则删除这个关键帧。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;45-回环检测&quot;&gt;4.5 回环检测&lt;/h4&gt;
&lt;p&gt;回环检测（Loop Closing）的主要目标是检测当前关键帧是否经过历史位置。如有经过，则利用回环检测得到的回环帧去修正整个SLAM长期跟踪过程中带来的累积误差、尺度漂移等。如果仅有前两个线程的话，仅仅完成了一个很好的视觉里程计（VO），这个线程会对全局地图以及关键帧进行回环检测，以消除上述累积误差。主要包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;候选关键帧检测：当前关键帧仅有与历史关键帧足够相似才可能成为回环候选帧，该模块通过一定的筛选策略对当前关键帧进行筛选，判断其是否为闭环候选关键帧。由于在实际闭环检测过程中，回环候选帧及其共视关键帧，在一定连续的时间内都可能被观测到。该模块主要通过利用这一条件，对闭环候选关键帧进一步地筛选，通过筛选条件的候选关键帧将进行下一步的判断。&lt;/li&gt;
  &lt;li&gt;相似性变换计算：考虑到单目SLAM的尺度漂移，当前帧和回环帧之间的相对位姿应是一个相似变换，并且，二者之间应具有足够多的匹配点。该模块主要是通过循环计算当前帧和上述经过筛选后的候选关键帧之间的相似变换，直到找到一个和当前帧具有足够多匹配点的相似变换，对应的候选关键帧即为最终的回环帧。&lt;/li&gt;
  &lt;li&gt;回环修正：受累积误差的影响，时间越久，越接近当前帧的关键帧及相应的地图点，误差将越大。若寻找到的回环帧，当前帧位姿及其对应的地图点会更精确。该模块就是为了修正累积误差，利用回环帧及其共视关键帧，以及对应的地图点，来修正当前帧及其共视关键帧的位姿以及对应的地图点的世界坐标。紧接着进行地图点融合，更新共视图，然后通过本质图优化相机位姿，最后进行全局BA来修正整个SLAM的累积误差（相机位姿以及地图点）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;五2d栅格地图的构建&quot;&gt;五、2D栅格地图的构建&lt;/h2&gt;
&lt;p&gt;通过上一章介绍，已经可以得到环境的3D结构信息。由3D环境信息获得2D平面图，只需要沿高度轴将3D结构图投影到2D平面即可，如图5.1。因为相机的Z轴对应于物理世界的Y轴，所以建立的2D地图就是3D地图的xz平面。
&lt;img src=&quot;../img/ORBSLAM/3D.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;51-构建方法&quot;&gt;5.1 构建方法&lt;/h4&gt;
&lt;p&gt;首先将ＯＲＢＳＬＡＭ中生成的所有关键帧投射到xz平面，这一投影可以通过去除关键帧中y轴的信息获得。对于每一个关键帧，对其所有的关键点进行操作，首先从相机的位置开始向每一个点处按照布雷森汉姆直线算法绘点（Bressenham’s line drawing algorithm）[14]，然后对xz平面的每一个位置处增加两个个计数器：访问计数器V和占用计数器O，分别用来统计映射到xz平面上该位置处的访问点(visit)与关键点(occupied)的数量，访问点就是布雷森汉姆直线算法处理之后经过的点。访问计数器和占用计数器是与地图点大小相同的整数数组。
因为ORB SLAM2将XZ平面视为水平面，因此将点的y坐标视为其高度。处理完所有关键帧后，计算网格图中每个单元的占用概率为：
\(p_{free}(i,j)=1-\frac{occupied(i,j)}{visit(i,j)}\)
其中 $p_{free}(i,j)$ 表示此点不是障碍物的概率， $occupied(i,j)$ 表示投影到此位置的关键点数量， $visit(i,j)$ 表示投影到此位置的所有访问点的数量。这样就可以得到一副二维包含概率的二维地图，然后通过设置两个阈值free_thresh和occupied thresh，将概率大于的free_thresh点认为没有障碍，将概率小于occupied thresh的点作为障碍点，概率在二者之间的表示未知点。图5.2为对CSC数据集处理后的概率图及阈值化之后的二维地图。
&lt;img src=&quot;../img/ORBSLAM/2D.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;52-局部与全局计数器&quot;&gt;5.2 局部与全局计数器&lt;/h4&gt;
&lt;p&gt;应用局部和全局计数器的想法源于3D点到XZ平面的简单2D投影的问题。所谓全局计数器是指在所有关键帧处理完之后，在计算每一个位置点处的占有情况，而局部计数器是指在处理完一帧后就计数，然后将数据叠加。首先考虑单个关键帧的情况，其中多个点的投影在2D平面中是共线的，如图5.4。在这种情况下，如果我们仅使用一个全局计数器来生成2D地图，有可能会得到一些不准确的地图信息。如图5.4中的中间点实际是有被占用的，但是由于上面一条线与下面一条重合，导致在计数时此位置只统计到了一个访问点而漏掉了占用点。这意味着，如果仅使用全局计数器，我们有可能将一些障碍认为是空闲的区域。
&lt;img src=&quot;../img/ORBSLAM/usingcount.jpg&quot; alt=&quot;&quot; /&gt;
图5.3显示了在CSC数据集上使用和不使用局部计数器的比较。我们可以看到，如果不使用本地计数器，很多实际占用的点将被替换为可用空间。
&lt;img src=&quot;../img/ORBSLAM/error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;六结果展示&quot;&gt;六、结果展示&lt;/h2&gt;
&lt;p&gt;本部分主要测试该算法的性能以及实际效果。图6.1是带有相机运动轨迹的点云图，
&lt;img src=&quot;../img/ORBSLAM/part.png&quot; alt=&quot;&quot; /&gt;
图6.2是一个闭环的点云俯视图。
&lt;img src=&quot;../img/ORBSLAM/part2.png&quot; alt=&quot;&quot; /&gt;
分析局部图发现人眼几乎很难分辨处详细信息，但是从完整闭环图中可以发现，点云还是能够包含3D场景的大部分信息。由于测试环境较为开放，如图6.2在构建的地图因为捕获的远近处的特征点都很多，所以导致看起来比较乱。图6.3是从网上下载的数据集进行测试的效果，隐去关键帧以及相机轨迹线之后，可以发现在相对封闭的环境中构建的3D地图相对较好。
&lt;img src=&quot;../img/ORBSLAM/zoudao.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;测试将3D地图映射为概率图以及二值化获得二维栅格的图的效果。如图6.4为将ORBSLAM产生点云映射到二维平面后的概率图，图6.5表示对概率图阈值化之后得到的栅格图。&lt;/strong&gt;
&lt;img src=&quot;../img/ORBSLAM/gailv.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;../img/ORBSLAM/result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本次实验主要测试同时运行ORBSLAM2建图以及2D建图的效果及其建图速度。如图6.6，在ORBSLAM２回环检测完毕后，二维地图也能马上完成构建，并且在运行的过程中没有掉帧等现象。&lt;/strong&gt;
&lt;img src=&quot;../img/ORBSLAM/real.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文首先分析了普通单目相机 的内外参数，并对使用相机进行了标定。然后介绍了视觉SLAM中几种算法，然后在ORBSLAM2构建的3D点云图上实现了二维地图的构建。在最终的实验中发现基于本文提出的2D地图构建方法能够实现较为完善的2D地图构建，而且其实时性也很好，可以满足机器人的实时导航需求。
本文并没有将产生的2D地图应用于实际机器人的导航中，后续的工作可以将其应用于实际的机器人导航系统中进行测试。采用本文方法可以使用普通的单目相机代替激光雷达或者RGBD相机，能够进一步的降低自主导航机器人的成本。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Ting S L, Kwok S K, Tsang A H C, et al. The study on using passive RFID tags for indoor positioning[J]. International journal of engineering business management, 2011, 3: 8.&lt;/li&gt;
  &lt;li&gt;张炎华, 王立瑞, 战兴群等. 惯性导航技术的新进展和发展趋势. 中国造船, 2008, 10(183): 134～144&lt;/li&gt;
  &lt;li&gt;Riisgaard S, Blas M R. SLAM for Dummies[J]. A Tutorial Approach to Simultaneous Localization and Mapping, 2003, 22(1-127): 126&lt;/li&gt;
  &lt;li&gt;Scharstein D, Szeliski R. High-accuracy stereo depth maps using structured light[C]//Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on. IEEE, 2003, 1: I-I.&lt;/li&gt;
  &lt;li&gt;Pollefeys M, Koch R, Van Gool L. Self-calibration and metric reconstruction inspite of varying and unknown intrinsic camera parameters[J]. International Journal of Computer Vision, 1999, 32(1): 7-25.&lt;/li&gt;
  &lt;li&gt;Zhang Z. Camera Extrinsic Parameters[M]//Computer Vision. Springer US, 2014: 77-77.&lt;/li&gt;
  &lt;li&gt;Ke Y, Sukthankar R. PCA-SIFT: A more distinctive representation for local image descriptors[C]//Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on. IEEE, 2004, 2: II-II.&lt;/li&gt;
  &lt;li&gt;Heikkila J, Silven O. A four-step camera calibration procedure with implicit image correction[C]//cvpr. 1997, 97: 1106.&lt;/li&gt;
  &lt;li&gt;张吴明, 钟约先. 基于改进差分进化算法的相机标定研究[D]. , 2004.&lt;/li&gt;
  &lt;li&gt;Ke Y, Sukthankar R. PCA-SIFT: A more distinctive representation for local image descriptors[J]. CVPR (2), 2004, 4: 506-513.&lt;/li&gt;
  &lt;li&gt;Wang X, Thibodeau B, Trope M, et al. Histologic characterization of regenerated tissues in canal space after the revitalization/revascularization procedure of immature dog teeth with apical periodontitis[J]. Journal of endodontics, 2010, 36(1): 56-63.&lt;/li&gt;
  &lt;li&gt;Machniewicz T. Fatigue crack growth prediction models for metallic materials Part II: Strip yield model–choices and decisions[J]. Fatigue &amp;amp; Fracture of Engineering Materials &amp;amp; Structures, 2013, 36(4): 361-373.&lt;/li&gt;
  &lt;li&gt;Mur-Artal R, Montiel J M M, Tardos J D. ORB-SLAM: a versatile and accurate monocular SLAM system[J]. IEEE transactions on robotics, 2015, 31(5): 1147-1163.&lt;/li&gt;
  &lt;li&gt;Van Aken J R. An efficient ellipse-drawing algorithm[J]. IEEE Computer Graphics and Applications, 1984, 4(9): 24-35.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 30 Aug 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/08/30/%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9B%B8%E6%9C%BA%E5%BE%972D%E5%9C%B0%E5%9B%BE%E6%9E%84%E5%BB%BA/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/08/30/%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9B%B8%E6%9C%BA%E5%BE%972D%E5%9C%B0%E5%9B%BE%E6%9E%84%E5%BB%BA/</guid>
        
        <category>ORBSLAM</category>
        
        <category>grid</category>
        
        
      </item>
    
      <item>
        <title>tensorflow神经网络学习笔记</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;本文介绍tensorflow中的一些基本概念，并说明如何可视化训练过程&lt;/p&gt;
  &lt;h4 id=&quot;variable&quot;&gt;Variable&lt;/h4&gt;
  &lt;p&gt;在 Tensorflow 中，定义了某字符串是变量，它才是变量，这一点是与 Python 所不同的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;定义语法： &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;state = tf.Variable()&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf

state = tf.Variable(0, name='counter')

# 定义常量 one
one = tf.constant(1)

# 定义加法步骤 (注: 此步并没有直接计算)
new_value = tf.add(state, one)

# 将 State 更新成 new_value
update = tf.assign(state, new_value)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;如果你在 Tensorflow 中设定了变量，那么初始化变量是最重要的&lt;/strong&gt;! 所以定义了变量以后, 一定要定义 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;init = tf.initialize_all_variables()&lt;/code&gt; .&lt;/p&gt;

&lt;p&gt;到这里变量还是没有被激活，需要再在 sess 里, sess.run(init) , 激活 init 这一步.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 如果定义 Variable, 就一定要 initialize
# init = tf.initialize_all_variables() # tf 马上就要废弃这种写法
init = tf.global_variables_initializer()  # 替换成这样就好
 
# 使用 Session
with tf.Session() as sess:
    sess.run(init)
    for _ in range(3):
        sess.run(update)
        print(sess.run(state))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;注意：直接 print(state) 不起作用！！&lt;/p&gt;

&lt;p&gt;一定要把 sess 的指针指向 state 再进行 print 才能得到想要的结果！&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;placeholder&quot;&gt;placeholder&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;placeholder&lt;/code&gt; 是 Tensorflow 中的占位符，暂时储存变量.
Tensorflow 如果想要&lt;strong&gt;从外部传入data, 那就需要用到 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.placeholder()&lt;/code&gt;&lt;/strong&gt;, 然后以这种形式传输数据 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sess.run(***, feed_dict={input: **})&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf

#在 Tensorflow 中需要定义 placeholder 的 type ，一般为 float32 形式
input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)

# mul = multiply 是将input1和input2 做乘法运算，并输出为 output 
ouput = tf.multiply(input1, input2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接下来, &lt;strong&gt;传值的工作交给了 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sess.run()&lt;/code&gt;&lt;/strong&gt; , 需要传入的值放在了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feed_dict={}&lt;/code&gt; 并一一对应每一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input. placeholder&lt;/code&gt; 与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feed_dict={}&lt;/code&gt; 是绑定在一起出现的。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with tf.Session() as sess:
    print(sess.run(ouput, feed_dict={input1: [7.], input2: [2.]}))
# [ 14.]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h4 id=&quot;add_layer&quot;&gt;add_layer&lt;/h4&gt;
&lt;p&gt;定义一个添加神经层的函数对与以后构建神经网络会有很大的便利性。
神经层里常见的参数有weights，biases和激活函数。
函数参数包括输入值以及输入值的大小，输出的大小以及激活函数。
初始化的时候weights随机生成，biases不推荐为0，所以加0.1。
wx_plus_b表示未激活的输出值。&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def add_layer(inputs, in_size, out_size, activation_function=None):
    Weights = tf.Variable(tf.random_normal([in_size, out_size]))
    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)
    Wx_plus_b = tf.matmul(inputs, Weights) + biases
    if activation_function is None:
        outputs = Wx_plus_b
    else:
        outputs = activation_function(Wx_plus_b)
    return outputs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h4 id=&quot;一元二次函数的训练&quot;&gt;一元二次函数的训练&lt;/h4&gt;

&lt;p&gt;定义一个单输入单输出，隐藏层包含十个神经元的网络结构进行训练。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf
import numpy as np

def add_layer(inputs, in_size, out_size, activation_function=None):
    Weights = tf.Variable(tf.random_normal([in_size, out_size]))
    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)
    Wx_plus_b = tf.matmul(inputs, Weights) + biases
    if activation_function is None:
        outputs = Wx_plus_b
    else:
        outputs = activation_function(Wx_plus_b)
    return outputs

#导入数据，并加入noise
x_data = np.linspace(-1,1,300, dtype=np.float32)[:, np.newaxis]
noise = np.random.normal(0, 0.05, x_data.shape).astype(np.float32)
y_data = np.square(x_data) - 0.5 + noise

#数据以placeholder格式输入，1表示只有一个特征，None表示不限大小
xs = tf.placeholder(tf.float32, [None, 1])
ys = tf.placeholder(tf.float32, [None, 1])

 
#构建1*10*1的神经网络
l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)  
prediction = add_layer(l1, 10, 1, activation_function=None)

loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),
                     reduction_indices=[1]))

train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

init = tf.global_variables_initializer()  # 替换成这样就好

sess = tf.Session()
sess.run(init)

for i in range(1000):
    # training
    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})
    if i % 50 == 0:
        # to see the step improvement
        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;for循环里面xs如何更新的--for表示训练轮数每一轮都把所有的数据给处理完&quot;&gt;for循环里面xs如何更新的?  &lt;strong&gt;for表示训练轮数，每一轮都把所有的数据给处理完。&lt;/strong&gt;&lt;/h2&gt;

&lt;h4 id=&quot;tensorboard-可视化&quot;&gt;tensorboard 可视化&lt;/h4&gt;
&lt;h6 id=&quot;显示网络结构&quot;&gt;显示网络结构&lt;/h6&gt;
&lt;p&gt;使用tensorboard可视化我们构建的网络，可以直观的显示出神经网络的结构。
&lt;img src=&quot;https://morvanzhou.github.io/static/results/tensorflow/4_1_1.png&quot; alt=&quot;1jpg&quot; /&gt;
可以点开每一个layer查看layer内部的元素。
&lt;img src=&quot;https://morvanzhou.github.io/static/results/tensorflow/4_1_2.png&quot; alt=&quot;2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;实现方式就是在需要显示的之前添加&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;with tf.name_scope('**'):&lt;/code&gt;,例如上面例子中添加如下：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from __future__ import print_function
import tensorflow as tf


def add_layer(inputs, in_size, out_size, activation_function=None):
    # add one more layer and return the output of this layer
    with tf.name_scope('layer'):
        with tf.name_scope('weights'):
            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')
        with tf.name_scope('biases'):
            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')
        with tf.name_scope('Wx_plus_b'):
            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)
        if activation_function is None:
            outputs = Wx_plus_b
        else:
            outputs = activation_function(Wx_plus_b, )
        return outputs


# define placeholder for inputs to network
with tf.name_scope('inputs'):
    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')
    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')

# add hidden layer
l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)
# add output layer
prediction = add_layer(l1, 10, 1, activation_function=None)

# the error between prediciton and real data
with tf.name_scope('loss'):
    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),
                                        reduction_indices=[1]))

with tf.name_scope('train'):
    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

sess = tf.Session()

# tf.train.SummaryWriter soon be deprecated, use following
if int((tf.__version__).split('.')[1]) &amp;lt; 12 and int((tf.__version__).split('.')[0]) &amp;lt; 1:  # tensorflow version &amp;lt; 0.12
    writer = tf.train.SummaryWriter('logs/', sess.graph)
else: # tensorflow version &amp;gt;= 0.12
    writer = tf.summary.FileWriter(&quot;logs/&quot;, sess.graph)

# tf.initialize_all_variables() no long valid from
# 2017-03-02 if using tensorflow &amp;gt;= 0.12
if int((tf.__version__).split('.')[1]) &amp;lt; 12 and int((tf.__version__).split('.')[0]) &amp;lt; 1:
    init = tf.initialize_all_variables()
else:
    init = tf.global_variables_initializer()
sess.run(init)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;显示训练过程&quot;&gt;显示训练过程&lt;/h6&gt;
&lt;p&gt;训练过程中的参数变化也可以通过tensorboard显示，常用的是显示出权重的变化，loss的变化，准确率的变化等等。
loss变化：
&lt;img src=&quot;https://morvanzhou.github.io/static/results/tensorflow/4_2_3.png&quot; alt=&quot;&quot; /&gt;
layer参数变化：
&lt;img src=&quot;https://morvanzhou.github.io/static/results/tensorflow/4_2_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from __future__ import print_function
import tensorflow as tf
import numpy as np


def add_layer(inputs, in_size, out_size, n_layer, activation_function=None):
    # add one more layer and return the output of this layer
    layer_name = 'layer%s' % n_layer        #define a new var       因为不同的layer属于不同变量
    with tf.name_scope(layer_name):
        with tf.name_scope('weights'):
            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')
            tf.summary.histogram(layer_name + '/weights', Weights)      #绘制变量图，第一个是名字，第二个是图标要记录的变量
        with tf.name_scope('biases'):
            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')
            tf.summary.histogram(layer_name + '/biases', biases)
        with tf.name_scope('Wx_plus_b'):
            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)
        if activation_function is None:
            outputs = Wx_plus_b
        else:
            outputs = activation_function(Wx_plus_b, )
        tf.summary.histogram(layer_name + '/outputs', outputs)
    return outputs


# Make up some real data
x_data = np.linspace(-1, 1, 300)[:, np.newaxis]
noise = np.random.normal(0, 0.05, x_data.shape)
y_data = np.square(x_data) - 0.5 + noise

# define placeholder for inputs to network
with tf.name_scope('inputs'):
    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')
    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')

# add hidden layer
l1 = add_layer(xs, 1, 10, n_layer=1, activation_function=tf.nn.relu)
# add output layer
prediction = add_layer(l1, 10, 1, n_layer=2, activation_function=None)

# the error between prediciton and real data
with tf.name_scope('loss'):
    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),
                                        reduction_indices=[1]))
    tf.summary.scalar('loss', loss)

with tf.name_scope('train'):
    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

sess = tf.Session()
merged = tf.summary.merge_all()

writer = tf.summary.FileWriter(&quot;logs/&quot;, sess.graph)

init = tf.global_variables_initializer()
sess.run(init)

for i in range(1000):
    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})
    if i % 50 == 0:
        result = sess.run(merged,
                          feed_dict={xs: x_data, ys: y_data})
        writer.add_summary(result, i)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;reference&quot;&gt;reference&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/&quot;&gt;莫凡Python&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 24 Jul 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/07/24/tensorflow%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/07/24/tensorflow%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
        
        <category>tensorflow</category>
        
        <category>神经网络</category>
        
        
      </item>
    
      <item>
        <title>Central pattern generators(CPG)模型</title>
        <description>&lt;h2 id=&quot;central-pattern-generators&quot;&gt;Central pattern generators&lt;/h2&gt;
&lt;h2 id=&quot;1-前言&quot;&gt;1. 前言&lt;/h2&gt;
&lt;p&gt;控制运动的问题是神经科学和机器人学能够很好结合的领域。怎么在只接受简单的、低维的输入信号的同时产生高维有节奏的输出信号在机器人的运动控制中十分重要。为了解决这一问题，引入了&lt;strong&gt;Central pattern generators(CPGs)&lt;/strong&gt; 模型。&lt;/p&gt;

&lt;p&gt;中枢模式发生器(CPGs)是一种在无脊椎动物和脊椎动物中都存在的&lt;strong&gt;神经回路&lt;/strong&gt;，它可以在不接收节律输入的情况下产生神经活动的节律模式。“中枢(cenntral)”一词表明产生节律不需要感觉反馈。CPGs是许多基本节奏活动的基础，如咀嚼、呼吸和消化。它们也是无脊椎动物和脊椎动物运动神经回路的基本组成部分。CPG模型呈现了几个有趣的特性，包括分布式控制、处理冗余的能力、&lt;strong&gt;快速控制循环&lt;/strong&gt;以及允许&lt;strong&gt;通过简单的控制信号来调节运动&lt;/strong&gt;。这些性质转化为到数学模型时，CPGs就可以很好的运用于机器人的运动控制。
本文的结构如下：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;神经生物学中CPG&lt;/li&gt;
  &lt;li&gt;生物学中的CPG模型&lt;/li&gt;
  &lt;li&gt;运用CPG进行运动控制&lt;/li&gt;
  &lt;li&gt;CPG模型的建立&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-神经生物学中的cpg&quot;&gt;2. 神经生物学中的CPG&lt;/h2&gt;
&lt;p&gt;中枢模式发生器(CPG)是一种神经网络，它&lt;strong&gt;能够在没有任何来自感觉反馈或更高控制中心的节奏输入的情况下，产生协调的节奏活动模式&lt;/strong&gt;(抖腿。)。正如&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/7423199&quot;&gt;Delcomyn(1980)&lt;/a&gt;所述，它们是无脊椎动物和脊椎动物许多节律行为的基础。现在的研究已经证实这种输出的节奏是不需要感官信息的，在许多的生物中都能发现CPGs。虽然产生节奏并不需要感官反馈，但它在形成节奏模式方面起着非常重要的作用，这是保持CPGs和身体运动协调的基础。例如人在跑步机上会被跑步机引导着进行慢走或者是快跑&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/11240279&quot;&gt;Rossignol(2000)&lt;/a&gt;。实验表明CPG与感觉反馈之间存在紧密耦合,也就是说，它们的效果取决于运动周期内的时间&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/17008376&quot;&gt;Gossard, 2006&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;在一些动物实验中，发现通过低水平的刺激可以导致高频的动作。说明CPG是一种复杂的电路，它可以产生复杂的运动行为，而且可以在接收到简单输入信号的情况下实现较大的动作变化。所以从控制的角度，CPGs模型实现了某种内部模型，它只需要接受控制运动的命令就可以实现运动的变化。&lt;/p&gt;

&lt;p&gt;总而言之，脊椎动物的运动系统是这样组织的:脊髓cpg负责产生基本的节奏模式，而高级中枢(运动皮层、小脑和基底神经节)负责根据环境条件调节这些模式。这样的分布式组织呈现出几个特征:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(i)它减少了运动控制回路中的时间延迟(节律通过脊髓的短反馈回路与机械运动协调)。&lt;/li&gt;
  &lt;li&gt;(ii)大大降低了下行控制信号的维数。实际上，控制信号一般不需要指定肌肉活动，只需要调节CPG活动。&lt;/li&gt;
  &lt;li&gt;(iii)因此，它显著减少了高级中枢与脊髓之间的必要带宽。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-几种cpg模型&quot;&gt;3. 几种CPG模型&lt;/h2&gt;
&lt;p&gt;本节回顾为研究生物CPGs而开发的不同类型的数学模型，以及已建模的动物运动类型。&lt;/p&gt;

&lt;h4 id=&quot;31-不同层面的模型&quot;&gt;3.1 不同层面的模型&lt;/h4&gt;
&lt;p&gt;根据所研究的现象，CPG模型被设计为几个抽象层次，从详细的&lt;strong&gt;生物物理模型(detailed biophysical models)&lt;/strong&gt;，到&lt;strong&gt;连接主义模型(connectionist models)&lt;/strong&gt;，再到&lt;strong&gt;耦合振荡器(coupled oscillators)&lt;/strong&gt; 的抽象系统。在某些情况下，CPG模型被耦合到人体生物力学模拟中，在这种情况下，它们被称为神经力学模型。&lt;/p&gt;

&lt;p&gt;详细的生物物理模型是建立在&lt;a href=&quot;https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model&quot;&gt; Hodgkin Huxley type&lt;/a&gt;神经元模型的基础上的,也就是说神经元模型计算离子泵和离子通道如何影响膜电位和动作电位的产生。更多参考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://link.springer.com/article/10.1007/BF00203132&quot;&gt;Computer simulation of the segmental neural network generating locomotion in lamprey by using populations of network interneurons&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/8105036&quot;&gt;Computer simulations of nmda and non-nmda receptors mediated synaptic drive: Sensory and supraspinal modulation of neurons and small networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;连接主义模型使用简化的神经元模型，如泄漏积分器( leaky-integrator)神经元或 integrate-and-fire neurons。这些模型的重点在于网络特性(如半中心网络)如何产生节律性活动，以及不同的振荡神经回路如何通过神经元间的连接(如肢体内或肢体间的协调)实现同步。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.4.546&quot;&gt;Phase coupling in simulated chains of coupled neuronal oscillators representing the lamprey spinal cord&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;振荡器模型&lt;/strong&gt;是基于耦合非线性振荡器的数学模型来研究种群动力学,在这种情况下，振荡器代表一个完整的振荡中心(而不是单个神经元或一个小电路)的活动。这些模型的目的不是解释节律发生(假设存在振荡机制)，而是研究振荡器间耦合和固有频率的差异如何影响振荡中心总体内的同步和相位滞后。&lt;a href=&quot;http://e.guigon.free.fr/rsc/article/CollinsRichmond94.pdf&quot;&gt;Collins和Richmond(1994)&lt;/a&gt;的研究使用三种不同类型的振荡器(van der Pol、Stein and FitzHugh Nagumo)在给定的网络拓扑结构中获得相同的步态转变.
其他广泛使用的振荡器包括&lt;strong&gt;相位振荡器( phase oscillators)&lt;/strong&gt; (&lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-3-540-27835-1_25&quot;&gt;Buchli &amp;amp;Ijspeert,2004&lt;/a&gt;)和&lt;strong&gt;松冈振荡器( Matsuoka oscillators)&lt;/strong&gt; (&lt;a href=&quot;https://link.springer.com/article/10.1023/A:1008924521542&quot;&gt;Sakurama, 1999&lt;/a&gt;)。大部分的振荡器有对于一个给定的频率都有固定的波形。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://e.guigon.free.fr/rsc/article/CollinsRichmond94.pdf&quot;&gt;Hard-wired central pattern generators for quadrupedal locomotion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-cpgs模型控制机器人运动&quot;&gt;4. CPGs模型控制机器人运动&lt;/h2&gt;
&lt;p&gt;在机器人中实现的CPG模型类型包括&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/1545435/&quot;&gt;连接主义模型&lt;/a&gt;，&lt;a href=&quot;https://ieeexplore.ieee.org/document/1014741&quot;&gt;向量图&lt;/a&gt;和 &lt;a href=&quot;https://www.semanticscholar.org/paper/The-Dynamics-of-Legged-Locomotion%3A-Models%2C-and-Holmes-Full/55e98268486d798cbb6b2cc8c8669e261a60d707&quot;&gt;耦合振荡器系统&lt;/a&gt;。实际上，所有的实现都涉及到耦合微分方程集，这些微分方程集是数值集成的(在微控制器或处理器上)。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/1545435/&quot;&gt;Serpentine locomotion of a snake-like robot controlled by cyclic inhibitory CPG model&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/1014741&quot;&gt;Polynomial design of the nonlinear dynamics for the brain-like information processing of whole body motion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.semanticscholar.org/paper/The-Dynamics-of-Legged-Locomotion%3A-Models%2C-and-Holmes-Full/55e98268486d798cbb6b2cc8c8669e261a60d707&quot;&gt;The dynamics of legged locomotion: Models, analyses, and challenges&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CPG的模型已被用于控制各种不同类型的机器人和不同的运动方式。如：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0921889005001508&quot;&gt;由昆虫运动启发的六足和八足机器人&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://infoscience.epfl.ch/record/118456/files/tro2008.pdf&quot;&gt;游泳机器人&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://journals.sagepub.com/doi/10.1177/0278364907078089&quot;&gt;四足机器人&lt;/a&gt;，调节CPG活动的感官反馈可以实现在复杂地形下的稳定运动。&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://link.springer.com/article/10.1007/s10015-007-0479-z&quot;&gt;人形机器人&lt;/a&gt;:&lt;strong&gt;待扩展&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CPG模型用于控制机器人的运动，是可以作为替代基于有限状态机、正弦发生器以及预设参考轨迹等方法的一种新的控制方法。CPG模型用于控制时候有如下几个特点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;可以产生稳定的节奏模式，系统在受到瞬态扰动后可以迅速恢复其正常的节律。&lt;/li&gt;
  &lt;li&gt;非常适合分布式实施，对模块化机器人很有意义，如蛇形机器人。&lt;/li&gt;
  &lt;li&gt;CPG模型通常具有一些控制参数（例如驱动信号），其允许调节运动，例如速度和方向或甚至步态类型。因此，正确实施的CPG模型降低了控制问题的维数，使得更高级别的控制器（或学习算法）不需要直接产生多维电动机命令而仅需要更高级别的控制信号。&lt;/li&gt;
  &lt;li&gt;CPG非常适合集成传感器反馈信号。&lt;/li&gt;
  &lt;li&gt;CPG模型通常为学习和优化算法提供良好的基础。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-cpg模型的构建&quot;&gt;5. CPG模型的构建&lt;/h2&gt;
&lt;h4 id=&quot;51-建立模型标准&quot;&gt;5.1 建立模型标准&lt;/h4&gt;
&lt;p&gt;在构建CPG模型时，必须定义以下项目：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;CPG的一般体系结构。这包括振荡器或神经元的类型和数量。在机器人中，还涉及位置控制（即CPG的输出是提供给反馈控制器的期望关节角度）或扭矩控制（即CPG的输出直接控制由马达产生的扭矩）之间进行选择。&lt;/li&gt;
  &lt;li&gt;联轴器的类型和拓扑结构。这些将决定振荡器与所产生的步态之间的同步条件，即振荡器之间的稳定相位关系。&lt;/li&gt;
  &lt;li&gt;波形。这些将确定在一个循环期间每个关节角度将实际执行的轨迹。波形明显取决于所选（神经）振荡器产生的极限环的形状，但可以通过添加滤波器进行转换。&lt;/li&gt;
  &lt;li&gt;输入信号的影响，即控制参数如何调制重要量，例如频率，幅度，相位滞后（用于步态转换）或波形（例如，用于独立调节摆动和站立阶段）。&lt;/li&gt;
  &lt;li&gt;反馈信号的影响，即来自身体的反馈如何影响CPG的活动（例如根据环境条件加速或减速）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;设计CPG的一个主要困难是这五个设计轴都是强相互关联的。&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%8A%A8%E5%8A%9B%E7%B3%BB%E7%BB%9F&quot;&gt;动力系统理论&lt;/a&gt;可以帮助设计CPG。例如，该理论可以帮助确定何时在耦合振荡器系统中发生同步，这一时间点取决于耦合权重和固有频率等参数（ &lt;a href=&quot;http://web.mit.edu/nsl/www/preprints/Polyrhythms05.pdf&quot;&gt;Pham＆Slotine，2007&lt;/a&gt;）。特别地，它可以确定哪个相位差是稳定的和不稳定的，并且该知识可以用于设计朝着特定的锁相状态（例如特定步态）发展的耦合振荡器系统。考虑对称性对确定振荡器的数量和获得特定步态所需的耦合拓扑结构很有帮助（&lt;a href=&quot;http://web.mit.edu/nsl/www/preprints/Polyrhythms05.pdf&quot;&gt;Pham＆Slotine，2007&lt;/a&gt;; &lt;a href=&quot;https://infoscience.epfl.ch/record/130740/files/righetti08.pdf;&quot;&gt;Righetti＆Ijspeert，2008&lt;/a&gt;）。&lt;/p&gt;

&lt;h4 id=&quot;52-模型参数的获得&quot;&gt;5.2 模型参数的获得&lt;/h4&gt;
&lt;p&gt;对于CPG模型中的参数，可以使用&lt;strong&gt;监督学习&lt;/strong&gt;或者是&lt;strong&gt;非监督学习&lt;/strong&gt;的方式进行训练得到。
&lt;strong&gt;监督学习&lt;/strong&gt;方法适用于CPG应该产生的节奏模式已知的情况，局限就是只能获得已知的运动的模型(&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0921889004000399&quot;&gt;Nakanishi, 2004&lt;/a&gt;)。
当CPG的期望行为未由特定期望模式（如在监督学习中）定义时，可以使用&lt;strong&gt;无监督学习&lt;/strong&gt;技术。在无监督学习技术中，基于随机群体的优化算法（如进化算法）已被广泛用于设计类似CPG的模型（&lt;a href=&quot;https://www.worldscientific.com/doi/abs/10.1142/9789814354301_0011&quot;&gt;＆Bekey，1993&lt;/a&gt;）。这些算法的一个有趣特性是它们可以优化大量的成本函数（例如，成本函数不需要像梯度下降算法那样连续），并且它们不需要知道成本的梯度功能（通常不可用）。这使得它们非常适合优化机器人的性能测量，例如测量机器人运动的前进速度。优化的参数通常是固定神经网络架构中的突触权重和耦合振荡器系统中的耦合权重。
&lt;strong&gt;强化学习&lt;/strong&gt;作为一种非监督学习，使用&lt;strong&gt;强化学习&lt;/strong&gt;的方法来获得参数也是一个重要的方法，参考：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S089360800700024X&quot;&gt;Reinforcement learning for a biped robot based on a cpg-actor-critic method&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/1573569/&quot;&gt;Learning CPG-based biped locomotion with a policy gradient method&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0921889005001508&quot;&gt;Wave CPG model for autonomous decentralized multi-legged robot: Gait generation and walking speed control&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://infoscience.epfl.ch/record/118456/files/tro2008.pdf&quot;&gt;Online optimization of swimming and crawling in an amphibious snake robot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://journals.sagepub.com/doi/10.1177/0278364907078089&quot;&gt;Adaptive dynamic walking of a quadruped robot on natural ground based on biological concepts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://web.mit.edu/nsl/www/preprints/Polyrhythms05.pdf&quot;&gt;Stable concurrent synchronization in dynamic system networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://infoscience.epfl.ch/record/130740/files/righetti08.pdf;&quot;&gt;Pattern generators with sensory feedback for the control of quadruped locomotion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0921889004000399&quot;&gt;Learning from demonstration and adaptation of biped locomotion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S089360800700024X&quot;&gt;Reinforcement learning for a biped robot based on a cpg-actor-critic method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 29 May 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/05/29/CPG%E6%A8%A1%E5%9E%8B/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/05/29/CPG%E6%A8%A1%E5%9E%8B/</guid>
        
        <category>CPG</category>
        
        
      </item>
    
      <item>
        <title>卷积神经网络(CNN)与tensorflow</title>
        <description>&lt;h2 id=&quot;卷积神经网络&quot;&gt;卷积神经网络&lt;/h2&gt;

&lt;h4 id=&quot;简介&quot;&gt;简介&lt;/h4&gt;

&lt;p&gt;卷积神经网络结构如图：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/cnn.png?raw=true&quot; alt=&quot;cnn&quot; /&gt;
卷积神经网络与全链接神经网络结构类似，都是逐层前向传递，而且网络的训练过程也十分类似．一个卷积神经网络由５种结构组成，输入层，卷积层，池化层，全链接层，softmax层．&lt;/p&gt;

&lt;h4 id=&quot;输入层&quot;&gt;输入层&lt;/h4&gt;
&lt;p&gt;输入层就是整个神经网络的输入．&lt;/p&gt;

&lt;h4 id=&quot;卷积层&quot;&gt;卷积层&lt;/h4&gt;
&lt;p&gt;卷积层(concolutional layer)在卷积神经网络中被称为过滤器或者是内核．在tensorflow中卷积层就是称之为过滤器(filter)．过滤器可以将当前层神经网络中的一个子节点矩阵转化为下一层神经网络上的一个单位节点矩阵．单位节点矩阵指长和宽都为１，但是深度不限的节点矩阵．卷积层结构示意图：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/filter.png?raw=true&quot; alt=&quot;filter&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;什么是卷积&quot;&gt;什么是卷积&lt;/h6&gt;
&lt;p&gt;由于ＣＮＮ多用于处理图像数据，卷积都是离散形式的卷积．对于在整数Z上的函数f,g，卷积定义为：&lt;/p&gt;

\[(f*g)[n]=\sum_{m=-\infty}^{\infty}f[m]g[n-m]=\sum_{m=-\infty}^{\infty}f[n-m]g[m]\]

&lt;p&gt;过滤器的前向传播过程就是通过左侧小矩阵中的节点计算出右侧单位矩阵中节点的过程．假设$w_{x,y,z}^{i}$表示对于输出矩阵中的第i个节点，过滤器输入节点$(x,y,z)$的权重，使用$b^i$表示第i个输出节点对应的偏置项参数，那么单位矩阵中第I个节点的取值$g(i)$：&lt;/p&gt;

\[g(i)=f(\sum_{x=1}^2\sum_{y=1}^2\sum_{z=1}^3a_{x,y,z}×w_{x,y,z}^i+b^i)\]

&lt;p&gt;其中$a_{x,y,z}$是过滤器中节点$(x,y,z)$的取值，f是激活函数．下图展示了在给定a,$w^0$和$b^0$的情况下，使用ＲｅＬＵ　作为激活函数是g(0)的计算过程．&lt;strong&gt;图中的·表示点积，就是矩阵中对应的元素相乘&lt;/strong&gt;
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/compute%20g0.png?raw=true&quot; alt=&quot;compute g(0)&quot; /&gt;.&lt;/p&gt;

&lt;h6 id=&quot;卷积层的前向传播&quot;&gt;卷积层的前向传播&lt;/h6&gt;
&lt;p&gt;上面介绍了一个过滤器的前向传播，&lt;strong&gt;卷积层的前向传播就是通过将一个过滤器从神经网络当前层的左上角移动到右下角，并且在移动的过程中计算每一个对应的单位矩阵得到&lt;/strong&gt;.下图展示了在3&lt;em&gt;3的矩阵上使用2&lt;/em&gt;2的过滤器时卷积层的前向传播．首先将过滤器用于左上角矩阵，在到右上角矩阵，类似的到右下角，过滤器每次移动一个格子，每移动一次，就可以计算的到一个值（深度为k的时候就会得到k个值）．将这些值拼成一个新的矩阵，就完成了卷积层的前向传播．
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/cnn%20forwd%20process.png?raw=true&quot; alt=&quot;cnn forwd process&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积层使用不为１＊１的过滤器时，得到的矩阵会小于当前矩阵，为了让其不缩小，可以使用０补全边缘．
过滤器移动时步长的大小也会影响前向传播得到的矩阵大小，例如长和宽的步长都是２的时候，得到的结果矩阵也只有原来的一半．
注：每一个卷积层使用的过滤器的参数是一样的，这样可以可以巨幅减少神经网络的参数．&lt;/p&gt;

&lt;h6 id=&quot;tensorflow实现ｃｎｎ&quot;&gt;tensorflow实现ＣＮＮ　&lt;/h6&gt;
&lt;p&gt;实现&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#通过tf.get_variable的方式创建过滤器的权重以及偏置项．卷积层的参数个数只和过滤器的尺寸，
#深度以及当前层的节点矩阵深度有关,所以这里声明的参数变量是一个四维矩阵，前面两维代表滤波器
#的尺寸，第三个表示当前层的深度，第四表示过滤器的深度
filter_weight = tf.get_variable(
    'weights',[5, 5, 3, 16],
    initializer = tf.truncated_normal_initializer(stddev=0.1))
#和权重类似，偏执层也是共享的，共有下一层深度个不同的偏置项,这里是１６
biases =  tf.get_variable(
    'biases', [16],initializer = tf.comstant_initializer(0.1))
#tf.nn.conv2d实现卷积层的前向传播．第一个输入参数是当前层的节点矩阵; 该矩阵是一个四维的，
#第一个维对应一个输入batch．例如input[0, ;, ;,;,]表示第一张图片，input[１, ;, ;,;,]表示第二张图片,
#后面三个维度对应一个节点矩阵．　　第二个参数提供了卷积层的权重，　　第三个参数为不同维度
#上的步长，该参数是程度为４的数组，注意该数组的第一位和最后一位必须是１．　　　最后一个参数
#是填充的方法．ＳＡＭＥ表示全０填充，ＶＡＬＩＤ表示不填冲
conv = tf.nn.conv2d(
    input, filter_weight, strides = [1, 1, 1, 1], padding = 'SAME')
#给每一个节点都加上偏置项
bias = tf.nn.bias_add(conv, biases)
#通过ＲｅＬＵ去线性化
actived_conv = tf.nn.relu(bias)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;池化层&quot;&gt;池化层&lt;/h4&gt;
&lt;p&gt;池化层(pooling layer)可以非常有效的缩小矩阵的尺寸，从而减少最后全链接层中的参数．使用池化层既可以加快计算速度也有防止过拟合的作用．&lt;/p&gt;

&lt;h6 id=&quot;池化层的前向传播&quot;&gt;池化层的前向传播&lt;/h6&gt;
&lt;p&gt;池化层与卷积层类似，也是通过移动一个滤波器来完成的．不同的是过滤器中的计算不是节点的加权求和，而是采用取最大值或者是求平均值．使用最大值操作的池化层被称为最大池化层（max pooling），这种结构使用的比较多．使用平均操作的池化层称为平均池化层(average pooling). 池化层中的过滤器也需要设置过滤器的尺寸，是否使用全０填充以及过滤器移动的步长等，这些设置的意义都是一样的．卷积层和池化层中过滤器的移动是类似的，唯一的区别就是卷积层中的过滤器是横跨整个深度的，而池化层的过滤器只影响一个深度上的节点．所以池化层的过滤器除了在长宽上移动还要在深度上移动．下图展示了最大池化层的前向传播计算过程．
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/pooling%20forward.png?raw=true&quot; alt=&quot;pooling forwd process&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;tensorflow实现&quot;&gt;tensorflow实现&lt;/h6&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#tf.nn.max_pool实现了最大池化层的前向传播，他的参数和tf.nn.conv2d函数类似
#ksize提供过滤器的尺寸，strides提供步长信息，padding提供是否使用全０填充
pool = tf.nn.max_pool(
    actived_conv, ksize=[1, 3, 3, 1],
    strides=[1, 2, 2, 1], padding = 'SAME')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;全连接层&quot;&gt;全连接层&lt;/h4&gt;
&lt;p&gt;经过几轮卷积与池化之后，可以认为输入图像中的信息已经被抽象成了信息含量更高的特征．可以将卷积与池化看作是图像特征提取的过程，在特征提取完毕后，仍然需要使用全连接层来完成分类任务．&lt;/p&gt;
&lt;h4 id=&quot;softmax层&quot;&gt;Softmax层&lt;/h4&gt;
&lt;p&gt;softmax层主要用于分类任务中，可以得到当前样例属于不同种类的概率分布情况．
—&lt;/p&gt;

&lt;h2 id=&quot;经典卷积神经网络模型&quot;&gt;经典卷积神经网络模型&lt;/h2&gt;
&lt;h4 id=&quot;lenet-5模型&quot;&gt;LeNet-5模型&lt;/h4&gt;
&lt;p&gt;LeNet-5模型结构如图：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/LeNet_5.png?raw=true&quot; alt=&quot;LeNet-5&quot; /&gt;
一共有七层，两层卷积，两层池化，三层全连接层．&lt;img src=&quot;&quot; alt=&quot;tensorflow实现的LeNet-5模型&quot; /&gt;．
该模型对手写数字集的识别有很好的效果，但是每一种模型都有其局限性，该模型无法很好的处理较大的图像数据集．&lt;/p&gt;
&lt;h6 id=&quot;设计卷积神经网络的架构&quot;&gt;设计卷积神经网络的架构&lt;/h6&gt;
&lt;p&gt;下面的正则表达式总结了一些经典的用于图像分类问题的卷积神经网络架构：
\(输入层\rightarrow(卷积层＋\rightarrow?)+\rightarrow全连接层＋\)
上面卷积层+表示一层或者多层卷积层，大部分的卷积神经网路中一般最多连续使用三层卷积层，池化层？表示没有或者一层池化层．池化层虽然可以起到减少参数防止过拟合的问题，但是调整卷积的步长也可以实现类似功能，所以有的俊基神经网络没有卷积层．在多层卷积和池化之后，卷积神经网络在输出之前会经过１－２个全连接层．&lt;/p&gt;
&lt;h4 id=&quot;inception-v3模型&quot;&gt;Inception-v3模型&lt;/h4&gt;
&lt;p&gt;该模型与LeNet-5模型有较大的区别，在LeNet-5模型中，不同卷积层是通过串联的方式连接在一起，但是在Inception-v3模型中的Inception结构是将不同的卷积层通过并联的方式结合在一起．
我们知道卷积层可以使用边长为１，３或者是５的过滤器，那么如何让在这些边长中选择呢？Inception给出了一个方案，就是同时使用所有不同尺寸的过滤器，然后得到的矩阵拼接起来．下图给出了Inception模块的一个单元结构示意图．
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/inception.png?raw=true&quot; alt=&quot;inception&quot; /&gt;
由图可以看出，inception模块首先使用不同尺寸的过滤器处理矩阵，不同的矩阵代表了inception的一条计算路径．虽然过滤器的大小不同，但是若所有的过滤器都使用全０填充，每次移动一步，则前向前向传播得到的结果矩阵的长和宽都合输入矩阵一直，这样经过不同的滤波器处理的结果矩阵可以拼成一个更深的矩阵．Inception-v3模型总共有４６层，由１１个inception模块构成．如下图：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/cnn/inception-v3.png?raw=true&quot; alt=&quot;inception-v3&quot; /&gt;
&lt;a href=&quot;&quot;&gt;Inception-v3模型的tensorflow实现代码参考&lt;/a&gt;．&lt;/p&gt;

</description>
        <pubDate>Mon, 06 May 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/05/06/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8Etensorflow/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/05/06/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8Etensorflow/</guid>
        
        <category>CNN</category>
        
        <category>tensorflow</category>
        
        
      </item>
    
      <item>
        <title>神经网络训练的tensorflow实现</title>
        <description>&lt;h2 id=&quot;神经网络训练的tensorflow实现&quot;&gt;神经网络训练的tensorflow实现&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;本文对神经网络训练步骤等进行说明，并说明了在tensorflow中相应的实现&lt;/p&gt;
  &lt;h3 id=&quot;神经网络训练过程的三个步骤&quot;&gt;神经网络训练过程的三个步骤：&lt;/h3&gt;
  &lt;ol&gt;
    &lt;li&gt;定义神经网络的结构和前向传播的输出结果。&lt;/li&gt;
    &lt;li&gt;定义损失函数以及选择神经网络的优化算法。&lt;/li&gt;
    &lt;li&gt;生成会话并在训练数据上反复运行神经网络优化算法
下面将根据这三部分进行相关概念的解释。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;一定义神经网络的结构以及前向传播结果&quot;&gt;一、定义神经网络的结构以及前向传播结果　&lt;/h3&gt;
&lt;h5 id=&quot;神经网络的结构&quot;&gt;神经网络的结构&lt;/h5&gt;
&lt;p&gt;主要包括输入输出节点数，以及隐藏层的深度以及每一层的节点数；&lt;/p&gt;
&lt;h5 id=&quot;前向传播&quot;&gt;前向传播&lt;/h5&gt;
&lt;p&gt;前向传播就是依据输入以及权重得到输出，前向传播算法如图所示(来自书本)：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/MNIST/qxcb%20.png?raw=true&quot; alt=&quot;&quot; /&gt;
前向传播算法一般表示为矩阵的形式，输入看成一个１＊２的矩阵$x=[x_1,x_2]$，将$W^{(1)}$表示为一个２＊３的矩阵：&lt;/p&gt;

\[W^{(1)}=
\begin{bmatrix}
W_{1,1}^{(1)} &amp;amp; W_{1,2}^{(1)} &amp;amp;W_{1,3}^{(1)}\\
W_{2,1}^{(1)} &amp;amp; W_{2,2}^{(1)} &amp;amp;W_{2,3}^{(1)}\\
\end{bmatrix}\]

&lt;p&gt;通过矩阵的乘法，可以得到隐藏层的节点输出为&lt;/p&gt;

\[a^{(1)}=[a_{11},a_{12},a_{13}]=xW^{1}=[x_1,x_2]
\begin{bmatrix}
W_{1,1}^{(1)} &amp;amp; W_{1,2}^{(1)} &amp;amp;W_{1,3}^{(1)}\\
W_{2,1}^{(1)} &amp;amp; W_{2,2}^{(1)} &amp;amp;W_{2,3}^{(1)}\\
\end{bmatrix}\]

&lt;p&gt;类似的输出层的结果可以表示为：&lt;/p&gt;

\[[y]=a^{1}W^{2}\]

&lt;p&gt;&lt;br /&gt;
需要注意到是，上面介绍的是线性化的神经网络结构，在应用中有很大局限性，&lt;strong&gt;线性模型可以解决的是那些可以用一条直线来划分开的问题&lt;/strong&gt;,神经网络经常使用使用激活函数实现去线性化.&lt;/p&gt;
&lt;h5 id=&quot;常用的激活函数&quot;&gt;常用的激活函数&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/MNIST/jhhs%20.png?raw=true&quot; alt=&quot;tu&quot; /&gt;
与线性模型前向传播的区别在于，每个节点的输出不再是简单的加权和，而是在加权之后经过一个非线性变换，此变换就是所使用的激活函数；同时多了一个&lt;strong&gt;偏置项&lt;/strong&gt;，偏置项的作用是提高网络的鲁棒性（如在分类问题中，有偏置项的时候分类线就不一定过原点，否则必过原点）&lt;/p&gt;
&lt;h5 id=&quot;tensorflow中相关参数的定义&quot;&gt;tensorflow中相关参数的定义&lt;/h5&gt;
&lt;p&gt;例如这条代码&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;weights = tf.Variable(tf.random_normal([2,3], stddev))&lt;/code&gt;生成一个2×3的矩阵变量，矩阵中的元素是均值为０，标准差为２的随机数。总之在声明变量的时候要给出初始化这个变量的方法．有关参数更多信息，&lt;a href=&quot;https://www.jianshu.com/p/c69f25fcc4a4&quot;&gt;请参考(by 金色暗影)&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;二损失函数及反向传播算法&quot;&gt;二、损失函数及反向传播算法&lt;/h3&gt;
&lt;p&gt;神经网络的训练过程就是参数的设置过程，使用监督学习的方式进行训练．&lt;strong&gt;监督学习就是在标注数据集上，模型给出的预测结果要尽可能的接近真是答案&lt;/strong&gt;．&lt;/p&gt;
&lt;h4 id=&quot;损失函数&quot;&gt;损失函数&lt;/h4&gt;
&lt;p&gt;损失函数是用来定义神经网络模型的效果以及优化目标的．对于分类问题，损失函数常定义为交叉熵;　对于预测问题，常用均方误差函数．&lt;/p&gt;
&lt;h6 id=&quot;交叉熵&quot;&gt;交叉熵&lt;/h6&gt;
&lt;p&gt;交叉熵用来判断输出向量和期望向量的接近程度．给定两个概率p, q．通过q来表示p的交叉熵为：&lt;/p&gt;

\[H(p,q)=-\sum_{x}p(x)logq(x)\]

&lt;p&gt;注意到交叉熵刻画的是两个概率之间的距离，所以我们应该把神经网络的输出转变为概率的形式．可以使用softmax回归实现．softmax回归处理后的输出为：&lt;/p&gt;

\[softmax(y)_i=y_i^{'}=\frac{e^{yi}}{\sum_{j=1}^{n}e^{yi}}\]

&lt;p&gt;通过softmax，神经网络的输出被被用做置信度生成新的输出，新的输出满足概率的所有要求．
tensorflow中，交叉熵一般会与softmax一块使用，可以直接通过&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cross_entropy = tf.nn.softmax_cross_entropy_with_logits(y, y_)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;来计算交叉熵损失函数．其中y表示神经网络的输出，y_表示真实的结果．&lt;/p&gt;

&lt;h6 id=&quot;均方误差mse-mean-squared-error&quot;&gt;均方误差（MSE, mean squared error)&lt;/h6&gt;
&lt;p&gt;定义如下：&lt;/p&gt;

\[MSE(y,y^{'})=\frac{\sum_{i=1}^{n}(y_i-y_i^{'})^2}{n}\]

&lt;p&gt;其中$y_i$为一个batch中第i个数据的正确答案，$y_i^{‘}$是神经网络给出的预测值．tensorflow中实现均方误差的函数：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mse = tf.reduce_mean(tf.square(y_ - y))&lt;/code&gt;&lt;/p&gt;

&lt;h6 id=&quot;自定义损失函数&quot;&gt;自定义损失函数&lt;/h6&gt;
&lt;p&gt;tensorflow中支持用户自定义损失函数．更多参考：&lt;a href=&quot;https://blog.csdn.net/sinat_29957455/article/details/78369763&quot;&gt;ensorFlow自定义损失函数(by 修炼之路)&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;优化算法&quot;&gt;优化算法&lt;/h4&gt;
&lt;p&gt;优化算法的功能，是通过改善训练方式，来最小化(或最大化)损失函数$E(x)$.&lt;/p&gt;

&lt;p&gt;在神经网络的优化算法中，最常用的就是反向传播算法,其流程图如下．
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/MNIST/fxcb.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;反向传播算法就是一个迭代的过程，每次开始迭代时候，首先取一部分数据作为训练数据，称为batch．batch中的数据通过前向传播得到输出，与真实值对比得到误差，然后根据误差函数进行参数的更新．参数更新算法常选择梯度下降法，通过计算误差函数E相对于权重参数W的梯度，&lt;strong&gt;在损失函数梯度的相反方向上更新权重参数&lt;/strong&gt;．下图展示了梯度下降的原理及过程：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/MNIST/tdxjt.png?raw=true&quot; alt=&quot;&quot; /&gt;
根据梯度下降法，参数的更新公式为：&lt;/p&gt;

\[\theta_{n+1}=\theta_n-\eta\frac{\partial}{\partial\theta_n}J(\theta_n)\]

&lt;p&gt;其中，$\theta$是神经网络中的参数，$J(\theta)$是损失函数，$\eta$是学习率，也就是每次参数移动的幅值．
梯度下降法可能局部最小，只有损失函数是凸函数的时候才能达到全局最优解，而且计算时间长．随机梯度下降速度快，但是可能找不到最优解，在实际使用的时候经常使用二者的结合，即每次计算一小部分训练数据（batch）的损失函数，tensorflow中的实现函数为：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train_step = tf.train.AdamOptimizer(0.001).minimize(loss)&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&quot;神经网络的进一步优化&quot;&gt;神经网络的进一步优化&lt;/h4&gt;
&lt;h6 id=&quot;指数衰减学习率&quot;&gt;指数衰减学习率&lt;/h6&gt;
&lt;p&gt;通过指数衰减学习率可以让模型在训练前期快速的接近较优解，又可以保证模型在训练后期不会有太大的波动．tensorflow提供了一种指数衰减法学习率设置方法，其实现函数为：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.train.exponential_decay&lt;/code&gt;,该函数的功能与以下代码功能相同：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;decayed_learning_rate = learning_rate*decay_rate^(global_step / decay_steps)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;decayed_learning_rate　为每一轮优化时候选择的学习率， learning_rate　是初始学习率；decay_rate是衰减系数，decay_steps　表示衰减速度．函数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.train.exponential_decay&lt;/code&gt;可以通过设置参数staricase选择不同的衰减方式，当staricase被设置为True时，(global_step / decay_steps)会被转化为整数．学习率与迭代轮数的关系如下图：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/MNIST/zssj.png?raw=true&quot; alt=&quot;&quot; /&gt;
下面给出&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.train.exponential_decay&lt;/code&gt;使用的一个示范：
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;learning_rate = tf.train.exponential_decay(0.1, global_step, 100, 0.96, staircase = True)&lt;/code&gt;
设置了一个初始学习率为0.1，　每训练100次学习率乘0.96的指数衰减学习率．&lt;/p&gt;

&lt;h6 id=&quot;正则化解决过拟合问题&quot;&gt;正则化解决过拟合问题&lt;/h6&gt;
&lt;p&gt;神经网络训练的三种情况如图：
&lt;img src=&quot;https://github.com/CNyuzhang/CNyuzhang.github.io/blob/master/img/MNIST/gnh%20.png?raw=true&quot; alt=&quot;&quot; /&gt;
为了解决过拟合问题，常常使用正则化．正则化的思想是在损失函数中加入刻画模型复杂程度的指标．基本思想是&lt;strong&gt;通过限制权重大小，使得模型不能拟合训练数据中的随机噪声&lt;/strong&gt;．例如在优化的时候常常优化：$J(\theta)+\lambda R(w)$,　其中$R(w)$刻画模型的复杂程度，$\lambda$表示模型复杂损失在总损失中的比例．常用的$R(w)$有两种，分别为L1正则化：&lt;/p&gt;

\[R(w)=\left\|w\right\|_1=\sum_i \left|w_i\right|\]

&lt;p&gt;L2正则化：&lt;/p&gt;

\[R(w)={\left\|w\right\|_２}^2=\sum_i \left|w_i\right|^2\]

&lt;p&gt;tensorflow中计算L1, L2 正则化的损失函数类似，给出L2正则化函数&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;L2 = tf.contrib.layers.l2_regularizer(lambda)(w)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;滑动平均模型&quot;&gt;滑动平均模型&lt;/h6&gt;
&lt;p&gt;在采用随机梯度下降法训练神经网络时候，使用滑动平均模型可以在一定程度上提高最终模型在测试数据上的表现．tensorflow通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.train.ExponentialMovingAverage&lt;/code&gt;来实现滑动平均模型．在初始化滑动平均模型的时候，需要设置一个衰减率(&lt;strong&gt;decay&lt;/strong&gt;)，其值越大模型越趋于稳定，实际应用中常常设置为&lt;strong&gt;接近为１&lt;/strong&gt;的数.
为了使模型在训练前期可以更新的更快，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExponentialMovingAverage&lt;/code&gt;提供了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_updates&lt;/code&gt;参数来动态的设置decay的大小，每次使用的衰减率为：&lt;/p&gt;

\[\left\{decay,  \frac{1+num_updates}{10+num_updates} \right\}\]

&lt;hr /&gt;

&lt;h3 id=&quot;三生成会话并运行程序&quot;&gt;三、生成会话并运行程序&lt;/h3&gt;
&lt;p&gt;tensorflow是通过会话(session)来执行定义好的运算的．会话的生成的常用方式有两种,二者的区别以及使用方式如下．
&lt;strong&gt;方法一&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 创建一个会话
sess = tf.Session()
# 使用这个创建好的会话来得到关心的运算的结果。比如可以调用sess.run(result),
# 来得到张量result的取值
sess.run(...)
# 关闭会话使得本次运行中使用到的资源可以被释放
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf
# 创建一个会话，并通过Python中的上下文管理器来管理这个会话。
with tf.Session() as sess:
    # 使用这创建好的会话来计算关心的结果。
    sess.run(...)
# 不需要再调用“Session.close()”函数来关闭会话，
# 当上下文退出时会话关闭和资源释放也自动完成。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;一个完整的神经网络训练的例子是MNIST手写数字识别，&lt;a href=&quot;https://github.com/CNyuzhang/tensorflow-/blob/master/mycode/MNIST%E5%85%A5%E9%97%A8/MNIST.py&quot;&gt;请查看源码&lt;/a&gt;并对照本文进一步理解．&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;四trensorflow模型的持久化&quot;&gt;四、trensorflow模型的持久化&lt;/h3&gt;
&lt;p&gt;持久化就是让训练好的模型保存下来，然后下次可以直接加载模型，这样就不必每次训练。tensorflow提供了一个很简单的ＡＰＩ来实现这个功能.&lt;/p&gt;
&lt;h6 id=&quot;持久化代码&quot;&gt;持久化代码&lt;/h6&gt;
&lt;p&gt;通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.train.Saver&lt;/code&gt;来实现，具体使用方法参考如下代码：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf

v = tf.Variable(2,dtype=tf.float32,name=&quot;v&quot;)
v2 = tf.Variable(2,dtype=tf.float32,name=&quot;v2&quot;)

for var in tf.all_variables():
    print (var.name)
ema = tf.train.ExponentialMovingAverage(0.99)
maintain_average_op = ema.apply(tf.all_variables())
for var in tf.all_variables():
    print (var.name)
saver = tf.train.Saver()
with tf.Session() as sess:
    tf.global_variables_initializer().run()
    sess.run(tf.assign(v,10))
    sess.run(maintain_average_op)
    saver.save(sess,'model/model.ckpt')
    print (sess.run([v,ema.average(v)]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;保存完之后会出现三个文件，这是因为tensorflow会将计算图的结构和图上的参数分开进行保存。&lt;/p&gt;

&lt;h6 id=&quot;加载已保存的模型&quot;&gt;加载已保存的模型&lt;/h6&gt;
&lt;p&gt;可以直接加载已经持久化的图以及其参数，实现代码如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf
#直接加载持久化的图
saver = tf.train.import_meta_graph(&quot;/path/to/model/model.ckpt/model.ckpt.meta&quot;)
with tf.Session() as sess:
    saver.restore(sess, &quot;/path/to/model/model.ckpt&quot;)
    #通过张量的名称来获取张量
    print sess.run(tf.get_default_graph().get_tensor_by_name(&quot;add:0&quot;))
    #输出[3.]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;当然，持久化的模型可以允许部分加载，以及其他操作，这里不在叙述。需要了解更多操作的话在到网上找。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;还是对于ＭＮＩＳＴ手写数字识别问题，&lt;a href=&quot;https://github.com/CNyuzhang/tensorflow-/tree/master/mycode/MNIST%E5%85%A5%E9%97%A8/mnist_Practice%20example&quot;&gt;这个实现&lt;/a&gt;给出了一个最佳的实践样例。将训练与测试分开进行，并使用了一些使代码更易读的方式。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Fri, 19 Apr 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/04/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E7%9A%84tensorflow%E5%AE%9E%E7%8E%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/04/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E7%9A%84tensorflow%E5%AE%9E%E7%8E%B0/</guid>
        
        <category>tensorflow</category>
        
        <category>neuron-network</category>
        
        
      </item>
    
      <item>
        <title>markdown 简单使用</title>
        <description>&lt;h3 id=&quot;1-斜体和粗体&quot;&gt;1. 斜体和粗体&lt;/h3&gt;

&lt;p&gt;使用 * 和 ** 表示斜体和粗体。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;p&gt;这是 &lt;em&gt;斜体&lt;/em&gt;，这是 &lt;strong&gt;粗体&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;2-分级标题&quot;&gt;2. 分级标题&lt;/h3&gt;

&lt;p&gt;使用 === 表示一级标题，使用 — 表示二级标题。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;这是一个一级标题
============================

这是一个二级标题
--------------------------------------------------

### 这是一个三级标题
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。&lt;/p&gt;

&lt;h3 id=&quot;3-外链接&quot;&gt;3. 外链接&lt;/h3&gt;

&lt;p&gt;使用 [描述](链接地址) 为文字增加外链接。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;p&gt;这是去往 &lt;a href=&quot;https://cnyuzhang.github.io/&quot;&gt;本人博客&lt;/a&gt; 的链接。&lt;/p&gt;

&lt;h3 id=&quot;4-无序列表&quot;&gt;4. 无序列表&lt;/h3&gt;

&lt;p&gt;使用 *，+，- 表示无序列表。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无序列表项 一&lt;/li&gt;
  &lt;li&gt;无序列表项 二&lt;/li&gt;
  &lt;li&gt;无序列表项 三&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-有序列表&quot;&gt;5. 有序列表&lt;/h3&gt;

&lt;p&gt;使用数字和点表示有序列表。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;有序列表项 一&lt;/li&gt;
  &lt;li&gt;有序列表项 二&lt;/li&gt;
  &lt;li&gt;有序列表项 三&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;6-文字引用&quot;&gt;6. 文字引用&lt;/h3&gt;

&lt;p&gt;使用 &amp;gt; 表示文字引用。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;野火烧不尽，春风吹又生。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;7-行内代码块&quot;&gt;7. 行内代码块&lt;/h3&gt;

&lt;p&gt;使用 `代码` 表示行内代码块。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;p&gt;让我们聊聊 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;html&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&quot;8--代码块&quot;&gt;8.  代码块&lt;/h3&gt;

&lt;p&gt;使用 四个缩进空格 表示代码块。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;这是一个代码块，此行左侧有四个不可见的空格。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;9--插入图像&quot;&gt;9.  插入图像&lt;/h3&gt;

&lt;p&gt;使用 ![描述](图片链接地址) 插入图像。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/703764-605e3cc2ecb664f6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;我的头像&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;cmd-markdown-高阶语法手册&quot;&gt;Cmd Markdown 高阶语法手册&lt;/h1&gt;

&lt;h3 id=&quot;1-内容目录&quot;&gt;1. 内容目录&lt;/h3&gt;

&lt;p&gt;在段落中填写 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[TOC]&lt;/code&gt; 以显示全文内容的目录结构。&lt;/p&gt;

&lt;p&gt;[TOC]
github 不支持&lt;/p&gt;

&lt;h3 id=&quot;2-标签分类&quot;&gt;2. 标签分类&lt;/h3&gt;

&lt;p&gt;在编辑区任意行的列首位置输入以下代码给文稿标签：&lt;/p&gt;

&lt;p&gt;标签： 数学 英语 Markdown&lt;/p&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;p&gt;Tags： 数学 英语 Markdown&lt;/p&gt;

&lt;h3 id=&quot;3-删除线&quot;&gt;3. 删除线&lt;/h3&gt;

&lt;p&gt;使用 ~~ 表示删除线。&lt;/p&gt;

&lt;p&gt;&lt;del&gt;这是一段错误的文本。&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-注脚&quot;&gt;4. 注脚&lt;/h3&gt;

&lt;p&gt;使用 [^keyword] 表示注脚。&lt;/p&gt;

&lt;p&gt;这是一个注脚&lt;sup id=&quot;fnref:footnote&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:footnote&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;的样例。&lt;/p&gt;

&lt;p&gt;这是第二个注脚&lt;sup id=&quot;fnref:footnote2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:footnote2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;的样例。&lt;/p&gt;

&lt;h3 id=&quot;5-latex-公式&quot;&gt;5. LaTeX 公式&lt;/h3&gt;

&lt;p&gt;$ 表示行内公式：&lt;/p&gt;

&lt;p&gt;质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。&lt;/p&gt;

&lt;p&gt;$$ 表示整行公式：&lt;/p&gt;

\[\sum_{i=1}^n a_i=0\]

\[f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2\]

\[\sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}\]

&lt;p&gt;访问 &lt;a href=&quot;http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference&quot;&gt;MathJax&lt;/a&gt; 参考更多使用方法。&lt;/p&gt;

&lt;h3 id=&quot;6-加强的代码块&quot;&gt;6. 加强的代码块&lt;/h3&gt;

&lt;p&gt;支持四十一种编程语言的语法高亮的显示，行号显示。&lt;/p&gt;

&lt;p&gt;非代码示例：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install vim-gnome
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Python 示例：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_authorization&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;somefunc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'''A docstring'''&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# interesting
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Greater'&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SomeClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'''interpreter
... prompt'''&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;JavaScript 示例：&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
* nth element in the fibonacci series.
* @param n &amp;gt;= 0
* @return the nth element, &amp;gt;= 0.
*/&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;7-流程图&quot;&gt;7. 流程图&lt;/h3&gt;

&lt;h4 id=&quot;示例&quot;&gt;示例&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;language-flow&quot;&gt;st=&amp;gt;start: Start:&amp;gt;https://www.zybuluo.com
io=&amp;gt;inputoutput: verification
op=&amp;gt;operation: Your Operation
cond=&amp;gt;condition: Yes or No?
sub=&amp;gt;subroutine: Your Subroutine
e=&amp;gt;end

st-&amp;gt;io-&amp;gt;op-&amp;gt;cond
cond(yes)-&amp;gt;e
cond(no)-&amp;gt;sub-&amp;gt;io
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/e50b0996299d04e390e1de61fb8b4c6b9dc4dbc6/68747470733a2f2f63646f636f2e636f6d2f696d616765732f666c6f772e706e67&quot; alt=&quot;&quot; /&gt;
    github不支持流程图&lt;/p&gt;
&lt;h4 id=&quot;更多语法参考流程图语法参考by-lkkwxy&quot;&gt;更多语法参考：&lt;a href=&quot;https://www.jianshu.com/p/b421cc723da5&quot;&gt;流程图语法参考(by lkkwxy)&lt;/a&gt;&lt;/h4&gt;

&lt;h3 id=&quot;8-序列图&quot;&gt;8. 序列图&lt;/h3&gt;

&lt;h4 id=&quot;示例-1&quot;&gt;示例 1&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;language-seq&quot;&gt;Alice-&amp;gt;Bob: Hello Bob, how are you?
Note right of Bob: Bob thinks
Bob--&amp;gt;Alice: I am good thanks!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/54398dfd1f0ba2cbb4c9577c255d2a2ac6c8829f/68747470733a2f2f63646f636f2e636f6d2f696d616765732f73657175656e63652e706e67&quot; alt=&quot;&quot; /&gt;
 github 也不支持&lt;/p&gt;
&lt;h4 id=&quot;示例-2&quot;&gt;示例 2&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;language-seq&quot;&gt;Title: Here is a title
A-&amp;gt;B: Normal line
B--&amp;gt;C: Dashed line
C-&amp;gt;&amp;gt;D: Open arrow
D--&amp;gt;&amp;gt;A: Dashed open arrow
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;更多语法参考序列图语法参考by-智胜千军&quot;&gt;更多语法参考：&lt;a href=&quot;https://blog.csdn.net/zhishengqianjun/article/details/74065232&quot;&gt;序列图语法参考(by 智胜千军)&lt;/a&gt;&lt;/h4&gt;

&lt;h3 id=&quot;9-甘特图&quot;&gt;9. 甘特图&lt;/h3&gt;

&lt;p&gt;甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-gantt&quot;&gt;    title 项目开发流程
    section 项目确定
        需求分析       :a1, 2016-06-22, 3d
        可行性报告     :after a1, 5d
        概念验证       : 5d
    section 项目实施
        概要设计      :2016-07-05  , 5d
        详细设计      :2016-07-08, 10d
        编码          :2016-07-15, 10d
        测试          :2016-07-22, 5d
    section 发布验收
        发布: 2d
        验收: 3d
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;更多语法参考甘特图语法参考&quot;&gt;更多语法参考：&lt;a href=&quot;https://knsv.github.io/mermaid/#gant-diagrams&quot;&gt;甘特图语法参考&lt;/a&gt;&lt;/h4&gt;

&lt;h3 id=&quot;10-mermaid-流程图&quot;&gt;10. Mermaid 流程图&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-graphLR&quot;&gt;    A[Hard edge] --&amp;gt;|Link text| B(Round edge)
    B --&amp;gt; C{Decision}
    C --&amp;gt;|One| D[Result one]
    C --&amp;gt;|Two| E[Result two]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;更多语法参考mermaid-流程图语法参考&quot;&gt;更多语法参考：&lt;a href=&quot;https://knsv.github.io/mermaid/#flowcharts-basic-syntax&quot;&gt;Mermaid 流程图语法参考&lt;/a&gt;&lt;/h4&gt;

&lt;h3 id=&quot;11-mermaid-序列图&quot;&gt;11. Mermaid 序列图&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-sequence&quot;&gt;    Alice-&amp;gt;John: Hello John, how are you?
    loop every minute
        John--&amp;gt;Alice: Great!
    end
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;12-表格支持&quot;&gt;12. 表格支持&lt;/h3&gt;
&lt;p&gt;如下：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;| 项目        | 价格   |  数量  |
| --------   | -----:  | :----:  |
| 计算机     | \$1600 |   5     |
| 手机        |   \$12   |   12   |
| 管线        |    \$1    |  234  |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;显示效果：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;项目&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;价格&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;数量&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;计算机&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$1600&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;手机&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$12&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;管线&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;234&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;13-定义型列表&quot;&gt;13. 定义型列表&lt;/h3&gt;

&lt;dl&gt;
  &lt;dt&gt;名词 1&lt;/dt&gt;
  &lt;dd&gt;定义 1（左侧有一个可见的冒号和四个不可见的空格）&lt;/dd&gt;
  &lt;dt&gt;代码块 2&lt;/dt&gt;
  &lt;dd&gt;这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格）

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;代码块（左侧有八个不可见的空格）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&quot;14-html-标签&quot;&gt;14. Html 标签&lt;/h3&gt;

&lt;p&gt;Markdown 语法中嵌套 Html 标签，譬如，你可以用 Html 写一个纵跨两行的表格：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;table&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;th rowspan=&quot;2&quot;&amp;gt;值班人员&amp;lt;/th&amp;gt;
        &amp;lt;th&amp;gt;星期一&amp;lt;/th&amp;gt;
        &amp;lt;th&amp;gt;星期二&amp;lt;/th&amp;gt;
        &amp;lt;th&amp;gt;星期三&amp;lt;/th&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;李强&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;张明&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;王平&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
&amp;lt;/table&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
    &lt;tr&gt;
        &lt;th rowspan=&quot;2&quot;&gt;值班人员&lt;/th&gt;
        &lt;th&gt;星期一&lt;/th&gt;
        &lt;th&gt;星期二&lt;/th&gt;
        &lt;th&gt;星期三&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;李强&lt;/td&gt;
        &lt;td&gt;张明&lt;/td&gt;
        &lt;td&gt;王平&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;h3 id=&quot;15-内嵌图标&quot;&gt;15. 内嵌图标&lt;/h3&gt;

&lt;p&gt;本站的图标系统对外开放，在文档中输入&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;i class=&quot;icon-weibo&quot;&amp;gt;&amp;lt;/i&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;即显示微博的图标： &lt;i class=&quot;icon-weibo icon-2x&quot;&gt;&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;替换 上述 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i 标签&lt;/code&gt; 内的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;icon-weibo&lt;/code&gt; 以显示不同的图标，例如：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;i class=&quot;icon-renren&quot;&amp;gt;&amp;lt;/i&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;即显示人人的图标： &lt;i class=&quot;icon-renren icon-2x&quot;&gt;&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;更多的图标和玩法可以参看 &lt;a href=&quot;http://fortawesome.github.io/Font-Awesome/3.2.1/icons/&quot;&gt;font-awesome&lt;/a&gt; 官方网站。&lt;/p&gt;

&lt;h3 id=&quot;16-待办事宜-todo-列表&quot;&gt;16. 待办事宜 Todo 列表&lt;/h3&gt;

&lt;p&gt;使用带有 [ ] 或 [x] （未完成或已完成）项的列表语法撰写一个待办事宜列表，并且支持子列表嵌套以及混用Markdown语法，例如：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- [ ] **Cmd Markdown 开发**
    - [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率
    - [ ] 支持以 PDF 格式导出文稿
    - [x] 新增Todo列表功能 [语法参考](https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments)
    - [x] 改进 LaTex 功能
        - [x] 修复 LaTex 公式渲染问题
        - [x] 新增 LaTex 公式编号功能 [语法参考](http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers)
- [ ] **七月旅行准备**
    - [ ] 准备邮轮上需要携带的物品
    - [ ] 浏览日本免税店的物品
    - [x] 购买蓝宝石公主号七月一日的船票
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对应显示如下待办事宜 Todo 列表：&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;&lt;strong&gt;Cmd Markdown 开发&lt;/strong&gt;
    &lt;ul class=&quot;task-list&quot;&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率&lt;/li&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;支持以 PDF 格式导出文稿&lt;/li&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;新增Todo列表功能 &lt;a href=&quot;https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments&quot;&gt;语法参考&lt;/a&gt;&lt;/li&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;改进 LaTex 功能
        &lt;ul class=&quot;task-list&quot;&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;修复 LaTex 公式渲染问题&lt;/li&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;新增 LaTex 公式编号功能 &lt;a href=&quot;http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers&quot;&gt;语法参考&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;&lt;strong&gt;七月旅行准备&lt;/strong&gt;
    &lt;ul class=&quot;task-list&quot;&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;准备邮轮上需要携带的物品&lt;/li&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;浏览日本免税店的物品&lt;/li&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;购买蓝宝石公主号七月一日的船票&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:footnote&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;这是一个 &lt;em&gt;注脚&lt;/em&gt; 的 &lt;strong&gt;文本&lt;/strong&gt;。 &lt;a href=&quot;#fnref:footnote&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:footnote2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;这是另一个 &lt;em&gt;注脚&lt;/em&gt; 的 &lt;strong&gt;文本&lt;/strong&gt;。 &lt;a href=&quot;#fnref:footnote2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 15 Apr 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2019/04/15/markdown%E7%94%A8%E6%B3%95/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/04/15/markdown%E7%94%A8%E6%B3%95/</guid>
        
        <category>markdown</category>
        
        
      </item>
    
  </channel>
</rss>
